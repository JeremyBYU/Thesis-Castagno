This dissertation has developed and integrated methods to enable safe and robust small UAS urgent landing capabilities in complex urban environments with focus on perception, mapping, and flight planning necessary to support unprepared rooftop landings. To identify and quantify the risk of landing sites we present methods integrating a multitude of data sources through novel computation geometry algorithms and deep learning. 

Prior to this work, an sUAS needed to be near prepared sites or open terrain suitable for urgent landing. This dissertation has shown that within cities there may be hundreds of nearby flat rooftops available for landing. This drastic increase in landing site options requires on-board autonomy to be as \emph{prepared}, \emph{efficient}, and \emph{lazy} as possible. First, preparedness comes from preprocessing as much data as possible to accurately assess the risk level of landing sites and their surrounding environments. Never leave work to be done online during an emergency that can instead be done offline. Second, it is essential to be efficient by utilizing appropriate data structures and algorithms while also exploiting parallelism. For example, using spatial indexes vastly reduces spatial query execution time, heuristic choices should be guided by the environment (3D octile distance for 3D grids), and work should be partitioned into as many isolated tasks as possible while distributed in parallel asynchronously. Finally, software should attempt to be as lazy as possible by only executing functions that are actually needed. This is especially true for expensive computations, such as path planning, that need only be executed when required. No amount of algorithmic optimization will ever outperform a no-op (no operation).  These three principles have guided our research approach and contributed to numerous open source algorithms and datasets for the academic community. 


\section{Contributions}

The contributions of this dissertation include:

\begin{itemize}
    \item In Chapter 2, we proposed our algorithm Polylidar to extract non-convex polygons with interior holes from 2D point sets. The point set is firstly triangulated where the shape is extracted using efficient region growing of triangle simplices. Unlike other methods which extract polygons by taking the union of triangle sets, Polylidar carefully walks the boundary of the set while accounting for interior holes. We benchmark our proposed algorithm on several state-of-the art algorithms showing more than 4X speed improvement and comparable accuracy.  
    \item In Chapter 3, we extended Polylidar to extract polygons representing flat surfaces from a variety of 3D data sources such as unorganized 3D point clouds, organized 3D point clouds, and user-defined meshes. As part of this work we present a novel fast Gaussian Accumulator that can quickly identify dominant plane normals within a 3D scene. Flat surfaces of non-connected surfaces are extracted independently though our parallel region growing and polygon extraction routines. We evaluate our methods on five separate datasets showing the speed and versatility of our methods.
    \item In Chapter 4, we proposed a method for identifying the roof shape of buildings using deep learning from airborne LiDAR point clouds, satellite images, and building outline data. A prepossessing routine takes raw data and generates both an RGB and depth image for each rooftop. Over 4500 building roofs spanning three cities were manually classified and archived. This is the largest dataset for roof shape identification at the time of publication. A combination of a \ac{CNN} for feature extraction and a random forest for classification gave the best results with an accuracy of 86\% on test data sets.  We show that confidence thresholding can lead to greater than 95\% precision and 75\% recall in labeling flat-like roofs.
    \item In Chapter 5, we proposed a framework for assimilating \ac{GIS} data to identity and evaluate risk for emergency landing sites, uniquely including building rooftops. Our work not only identifies flat rooftops, but isolates obstacle-free flat surfaces on them and quantifies the \emph{usable} landing space thereon for risk evaluation. We presented a multi-goal planner that efficiently selected the landing site/path pair guaranteed to minimize a weighted total risk function. Several case studies and Monte Carlo simulations are conducted showing that our planner finds risk-optimal landing sites in  less than 50ms for 95\% of all cases.
    \item In Chapter 6, we proposed a hybrid computational geometry and deep neural network algorithm to identify and select safe rooftop landing zones in real-time using a combination of LiDAR and camera sensors. For testing, we created a high-fidelity simulated city in the Unreal game engine with particular attention given to creating a statistically accurate representation of rooftop obstacles. Results showed that our fusion of geometric and semantic information improved landing site identification accuracy over 4\%.
    \item In Chapter 7, we successfully evaluated our proposed methods for touchdown point selection with a drone platform. We used on-board solid state LiDAR and 6DOF tracking sensors to create full environmental meshes of an indoor flight environment. Obstacle-free flat surfaces were extracted with Polylidar3D and optimal touchdown points selected for autonomous landing. In all three flights a landing site was found and the drone landed successfully.
\end{itemize}
    % \item In Chapter 6, we proposed fusing Polylidar3D with with semantic segmentation for use in real-time landing site identification and selection
\section{Future Work}

Although this dissertation has presented multiple contributions in computational geometry, machine learning, and urgent landing for \ac{sUAS}, there are still many challenges to improve reliability of autonomous urgent landing in cities.  Specific challenges are discussed below.

\subsection{Robustly Segmenting Rooftop Point Clouds}

Chapter 4 proposed a general framework for identifying rooftop shapes through RGB and depth images using CNNs. There have recently been many advances in deep learning which can operate more directly on 3D data \cite{qi_pointnet_2017-1, xu_spidercnn_2018, liu_dynamic_2019}. These neural network architectures sample from the point cloud and directly learn global and local geometric features of the point cloud surface. These methods have been shown to be successful in shape classification, object detection and tracking, and point cloud segmentation \cite{guo_deep_2020}. Our methods on rooftop landing site detection could be improved if aerial LiDAR point clouds could be more accurately segmented and classified before being given to Polylidar3D. Polylidar3D could then be modified to take advantage of these segmentation classes to provide a more robust estimate of landing areas.

% \subsection{Beyond Dominant Plane Normals for Polylidar3D}
\subsection{Improving Polylidar3D}

Polylidar3D is currently designed for extracting dominant planes within scenes such as floors and walls. This focus allows Polylidar3D to be extremely fast at grouping triangles that may belong to the same continuous surface and performing region growing of disparate regions in parallel. However, this limits Polylidar3D's use in applications that require detailed extraction of smaller surfaces within a 3D scene. Future work should investigate integrating new techniques that use Spherical Convex Hulls to iteratively refine surface normal estimates during region growing \cite{mols_highly_2020}. There is potential to combine our proposed Gaussian Accumulator for an initial estimate of planes and the Spherical Convex Hull for refinement and extraction of the remaining small surfaces. 

Polylidar3D was designed to be a versatile framework to take many forms of 3D input.  This versatility expands its applicability but creates a challenge for creating unified and optimized software. For example, there are many ways to further increase and parallelize Polylidar3D when working with range images. The structure of a range image allows neighbor information to be implicitly computed and does not need require explicit neighborhood data structures such as the half-edge neighbors of triangles. Optimized routines for each data input will allow further speedup and possibly improved accuracy with new techniques.

% Finally, semantic integration into Polylidar3D is currently quick, sufficient, yet quite rudimentary. Future work should investigate the possibility of using likelihood maximisation 
\subsection{Extending Touchdown Point Definition to Fixed-Wing Aircraft}

This work has focused on finding terrain and rooftop landing sites suitable for \ac{VTOL} \ac{sUAS} urgent landing within cities. Touchdown points on landing sites were found by calculating the largest inscribed circle of the polygonal representations of flat surfaces. These touchdown circles are ideal for \ac{VTOL} aircraft but are not suitable for fixed-wing aircraft which require a level strip of smooth ground, i.e., an unprepared runway, to support safe deceleration to a full stop. The flat terrain-based landing sites identified in this work may be suitable for fixed-wing aircraft if alternative touchdown locations are defined. Future work should investigate finding the longest inscribed  rectangle inside a non-convex polygon with sufficient width and length necessary for safe aircraft landing. This problem is related to prior work which finds a rotated rectangle with the largest area inside non-convex polygons \cite{molano_finding_2012}. However, the method cannot handle polygons with interior holes and optimizes for the area of the rectangle instead of its length. Future work should develop methods for finding multiple ``runways'' inside polygons that can optimize for the approach and roll-out of a fixed-wing aircraft needing immediate landing. Wind, nearby terrain, et al. must also be considered in future work.

\subsection{Remembering the Human Factor}

The risk models presented in Chapter \ref{ch:maplanding} assume that the overall risk of a decision is the sum of the magnitude of each attribute multiplied by a risk score. The choice of attributes and their magnitudes are subjective and require thoughtful human determination \cite{Wickens2015}. Future work should be performed to gather expert pilot opinions on whether the proposed attributes are sufficient and if additional metrics are needed. Participant will also rank, categorize, and group the most important attributes. Scenarios similar to the presented case studies in Chapter \ref{ch:maplanding} can be shown where pilots will choose a landing site/path pair. A fully integrated visualization of 2D maps, 3D environments, and risk graphs can be presented to allow research participants to make informed decisions. The result of this work will inform attribute and weight definitions in our final risk models.

In the event of an emergency, our proposed emergency planner can operate locally and autonomously; a data-link for remote operator action is not required. However, it may be desirable to give a time-limited opportunity for a remote human operator to participate in the emergency response process. Some failure scenarios may pose high-risk toward humans requiring an immediate decision for landing (i.e., sub-second). These situations do not allow elaborate human interaction with an emergency planner interface; we must prioritize the necessary speed of the autonomous system against the value a human operator may provide. A simple interface displaying the optimal landing site/path pair with a confirmation or ``go'' button may be used in such situations. These confirmation displays are often used in high risk situations, e.g., autonomous weapon defense systems where a human operator has less than one second to confirm the launch of intercepting missiles against incoming short-range rockets \cite{docherty2012losing}. However, many \ac{sUAS} failures will not pose immediate high risk to overflown populations such that more in depth human feedback may be beneficial. Humans in this role should not focus on low level details such as trajectory planning but act in a supervisory role by choosing the best course of action that is presented \cite{gutzwiller_human-computer_2015}.

For this purpose, an intuitive user interface for our emergency planner should be carefully defined. The type, amount, and form of information presented should be balanced with cognitive strain humans encounter during time-sensitive, high risk, and uncertain situations \cite{2003_technical_review_human_error}. Research indicates that humans in this ``problem-solving'' mode look for cues from data, perform hypothesis generation and selection, and finally action selection \cite{wickens_5_1988}. Therefore our user interface should be limited to elements that successfully aid humans through this decision making process. First, our emergency planner interface should have separate \emph{pre-takoff configuration} and \emph{emergency action selection} screens. The pre-takeoff screen allows a user to configure the mission specific constraints and attribute rankings for risk minimization during landing site selection. Constraints such as flight altitude, flight time, landing site distance, and landing site type (e.g., prepared or unprepared) should be able to be removed and added through the interface. Additionally, users may select an option to bias landing site rank to those closer to a critical destination point (e.g., a hospital) rather than being near the \ac{sUAS} itself. A slider can also be presented that changes the ranking of landing sites based on landing site or path risk metrics. This screen may be information dense as time is not a constraint during the pre-flight process. In contrast, during an urgent crisis the action selection screen must afford quick operator selection. Therefore, only the top ranked sites should be presented to the operator to bring attention to the most likely of choices. Concise summary views of each landing site and their paths should be available. The operator may then choose a final landing site/path pair. Future work should gather expert opinions of pilots and user interface design engineers to begin designing both interfaces.

\subsection{Gaining Confidence in the Data}

Our proposed methods have successfully identified thousands of additional landing sites within cities by finding rooftops suitable for landing. However, the maps we create are limited by the availability, accuracy, and resolution of the archived \ac{GIS} data sources. The characteristics of the underlying data may change over time and by location in the world. Future work should be done to quantify data quality and uncertainty while determining their effects for use in urgent landing. Examples of important attributes include the date and time of recording, satellite image resolution, point cloud spacing and noise, image occlusion and distortion, and many others. A common example of inaccurate data is when airborne LiDAR point clouds are several years old which may mislead our methods about the current state of the environment. Our methods attenuate these effects by fusing multiple data streams together (e.g., satellite and LiDAR data), but sometimes both modalities can be incorrect. Future work should be able to explicitly mark rooftops identified using low quality sources by attaching a ``grade'' that indicates its reliability.

Our methods for rooftop identification need not be limited to archived data sources. Future work should investigate methods of integrating real-time data streams from UAS into a remote cloud database. This data could then be processed in the cloud to significantly augment existing data and further reduce uncertainty. However, this does introduce new challenges as multiple datasets, possibly conflicting, must now be integrated. It is likely that this future work will require the use of distributed consensus algorithms to enforce data consistency \cite{raft_concensus}. Database changes could then be streamed to UAS with a datalink to provide the most up to date information.

\subsection{Creating a More Complete Picture of Risk}

The efforts in this dissertation have found hundreds of safe nearby landing zones by utilizing rooftops. Yet a complete quantification of the risks \ac{sUAS} pose to themselves, people, and property are difficult to accurately calculate. For example, quantifying the effects of wind on \ac{sUAS} trajectories is an important task left for future work. However, supporting a quick nearby landing that minimizes flight time, and knowing whether a rooftop is truly unoccupied \emph{at the time of landing} are keys to risk reduction. Yet high resolution temporal population information is missing from public datasets. Large corporations, such as Google and Apple, have access to this data through location tracking on mobile devices. The transformation and packaging of this and other personal data becomes the corporation's property and is either used internally or sold to business partners. This is an example of a centralized tracking program. However, the recent COVID-19 pandemic has shown that a decentralized, user-friendly, and anonymous location tracking program is not only possible but beneficial for public health \cite{cohen_digital_2020, lee_benefits_2021}. These opt-in applications have been used successfully during the COVID-19 pandemic to allow more rapid contact tracing during outbreaks. This same technology can be used to enable real-time anonymized population density information within cities to inform decision making for autonomous safety systems. A drone with real-time access to such a data stream can make a more informed choice for landing site selection and path planning.

A future is soon coming where there will be hundreds of autonomous drones navigating the urban skies. This will present challenges as drones will need to cooperate with each other when executing their individual missions. These challenges are similar to those facing the autonomous vehicles (AV) industry. Vehicle to Vehicle (V2V) communication is proposed as a solution which can increase the safety of passengers by sending and receiving local omni-directional messages informing vehicles of nearby potential accidents/crashes/threats. In addition, Vehicle to Infrastructure (V2I) communication can allow vehicles to send their position, velocity, and important observations to a centralized server. We critically need trusted datalink for next-generation air traffic management, system-wide.  Human voice communication has served us well but simply cannot scale.  A traffic management server can then inform others about traffic congestion and provide warnings for hazardous situations \cite{chitanvis_collision_2019}. \ac{UAS} can greatly benefit by utilizing V2V and V2I (V2I2V) techniques and NASA's proposed \acf{UTM} system would be an excellent fit for V2I functionality. A drone or future advanced air mobility taxi may ingest these local and cloud-based messages to create a more complete picture of local risks. 




% https://www.nhtsa.gov/technology-innovation/vehicle-vehicle-communication

% Better tracking of all participants. Bring 3D tracking of drones.

% Finally, any autonomous algorithm that decides an action which may effect human lives poses serious ethical questions. 

% tions similar to the questions currently under consideration for other autonomoussystems such as car


% https://apnews.com/article/north-america-science-technology-business-ap-top-news-828aefab64d4411bac257a07c1af0ecb
% \subsection{General Purpose Mapping with Polygons}



