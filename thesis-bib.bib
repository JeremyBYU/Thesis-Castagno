%% If I want to change to IEEE style references, I need this line to allow repeated authors names in citation list
%%  ------------ Use AT symbol here
%%  |
%%  ▼
%%  %IEEEtranBSTCTL{IEEEexample:BSTcontrol,CTLdash_repeated_names = "no"}
%% Dont forget to clear cache as well, Look at log file and look for trash icon


@incollection{castagno_map-based_2021,
  title = {Map-{{Based Planning}} for {{Small Unmanned Aircraft Rooftop Landing}} ({{In Press}})},
  booktitle = {Handbook on {{Reinforcement Learning}} and {{Control}}},
  author = {Castagno, Jeremy and Atkins, Ella},
  year = {2021},
  publisher = {{Springer}},
  annotation = {In Press.}
}




@inproceedings{10.1145/37401.37422,
  title = {Marching Cubes: {{A}} High Resolution {{3D}} Surface Construction Algorithm},
  booktitle = {Proceedings of the 14th Annual Conference on Computer Graphics and Interactive Techniques},
  author = {Lorensen, William E. and Cline, Harvey E.},
  year = {1987},
  pages = {163--169},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/37401.37422},
  abstract = {We present a new algorithm, called marching cubes, that creates triangle models of constant density surfaces from 3D medical data. Using a divide-and-conquer approach to generate inter-slice connectivity, we create a case table that defines triangle topology. The algorithm processes the 3D medical data in scan-line order and calculates triangle vertices using linear interpolation. We find the gradient of the original data, normalize it, and use it as a basis for shading the models. The detail in images produced from the generated surface models is the result of maintaining the inter-slice connectivity, surface data, and gradient information present in the original 3D data. Results from computed tomography (CT), magnetic resonance (MR), and single-photon emission computed tomography (SPECT) illustrate the quality and functionality of marching cubes. We also discuss improvements that decrease processing time and add solid modeling capabilities.},
  isbn = {0-89791-227-6},
  series = {{{SIGGRAPH}} '87}
}




@inproceedings{10.1145/237170.237269,
  title = {A Volumetric Method for Building Complex Models from Range Images},
  booktitle = {Proceedings of the 23rd Annual Conference on Computer Graphics and Interactive Techniques},
  author = {Curless, Brian and Levoy, Marc},
  year = {1996},
  pages = {303--312},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/237170.237269},
  isbn = {0-89791-746-4},
  keywords = {isosurface extraction,range image integration,surface fitting,three-dimensional shape recovery},
  series = {{{SIGGRAPH}} '96}
}




@article{castagno_polylidar3d_2020,
  title = {{{Polylidar3D}} - {{Fast Polygon Extraction}} from {{3D Data}}},
  author = {Castagno, Jeremy and Atkins, Ella},
  year = {2020},
  month = jan,
  volume = {20},
  pages = {4819},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  doi = {10.3390/s20174819},
  abstract = {Flat surfaces captured by 3D point clouds are often used for localization, mapping, and modeling. Dense point cloud processing has high computation and memory costs making low-dimensional representations of flat surfaces such as polygons desirable. We present Polylidar3D, a non-convex polygon extraction algorithm which takes as input unorganized 3D point clouds (e.g., LiDAR data), organized point clouds (e.g., range images), or user-provided meshes. Non-convex polygons represent flat surfaces in an environment with interior cutouts representing obstacles or holes. The Polylidar3D front-end transforms input data into a half-edge triangular mesh. This representation provides a common level of abstraction for subsequent back-end processing. The Polylidar3D back-end is composed of four core algorithms: mesh smoothing, dominant plane normal estimation, planar segment extraction, and finally polygon extraction. Polylidar3D is shown to be quite fast, making use of CPU multi-threading and GPU acceleration when available. We demonstrate Polylidar3D\&rsquo;s versatility and speed with real-world datasets including aerial LiDAR point clouds for rooftop mapping, autonomous driving LiDAR point clouds for road surface detection, and RGBD cameras for indoor floor/wall detection. We also evaluate Polylidar3D on a challenging planar segmentation benchmark dataset. Results consistently show excellent speed and accuracy.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\TYKIGHBT\\Castagno and Atkins - 2020 - Polylidar3D-Fast Polygon Extraction from 3D Data.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\JPLQPZIJ\\htm.html},
  journal = {Sensors},
  keywords = {geometry,LiDAR,mapping,point cloud,polygon},
  language = {en},
  number = {17}
}




@article{bleier_risk_2015,
  title = {Risk {{Assessment}} of {{Flight Paths}} for {{Automatic Emergency Parachute Deployment}} in {{UAVs}}},
  author = {Bleier, Michael and Settele, Ferdinand and Krauss, Markus and Knoll, Alexander and Schilling, Klaus},
  year = {2015},
  month = jan,
  volume = {48},
  pages = {180--185},
  issn = {2405-8963},
  doi = {10.1016/j.ifacol.2015.08.080},
  abstract = {This paper presents models for the risk assessment and generation of flight paths, which support the automatic deployment of emergency parachutes for unmanned aerial vehicles in emergencies due to loss of propulsion. Based on a risk analysis of the area underneath the flight path, suitable deployment positions are identified, which minimize the chance of endangering humans on the ground, property damage and loss of the air vehicle. Additionally, the flight path selection is guided by constraints, such as control data link availability or aircraft performance.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\Y88RFIJ4\\S2405896315009477.html},
  journal = {IFAC-PapersOnLine},
  keywords = {Autonomy,Decision making,Emergency planning,Trajectory generation,UAV},
  language = {en},
  number = {9},
  series = {1st {{IFAC Workshop}} on {{Advanced Control}} and {{Navigation}} for {{Autonomous Aerospace Vehicles ACNAAV}}'15}
}




@article{agarwal2002polygon,
  title = {Polygon Decomposition for Efficient Construction of {{Minkowski}} Sums},
  author = {Agarwal, Pankaj K and Flato, Eyal and Halperin, Dan},
  year = {2002},
  volume = {21},
  pages = {39--61},
  publisher = {{Elsevier}},
  journal = {Computational Geometry},
  number = {1-2}
}

@inproceedings{ahn_analysis_2019,
  title = {Analysis and {{Noise Modeling}} of the {{Intel RealSense D435}} for {{Mobile Robots}}},
  booktitle = {2019 16th {{International Conference}} on {{Ubiquitous Robots}} ({{UR}})},
  author = {Ahn, Min Sung and Chae, Hosik and Noh, Donghun and Nam, Hyunwoo and Hong, Dennis},
  year = {2019},
  month = jun,
  pages = {707--711},
  issn = {2325-033X},
  doi = {10.1109/URAI.2019.8768489},
  abstract = {Cameras that provide distance measurement along with RGB data have increasingly been appearing in the market as alternatives to the more expensive setup of LIDARs and webcams. While products such as the Kinect have existed in the past, its weight and form factor have been demanding constraints for mobile robots, specifically legged robots that are sensitive to payload. Recently Intel released a new lineup of Intel RealSense RGB-D cameras that have favorable characteristics for legged robots, specifically in terms of resolution, frames per second, form factor, weight, and price range. However, because these active stereo sensors are noisy for reasons such as non-overlapping image regions or lack of texture, it is beneficial to empirically model the noise. Systematic errors, specifically the distance inhomogeneity and depth bias, are observed to recognize and verify the limitations of the camera. We also analyze the non-systematic error by modeling both the axial and lateral noise as a function of distance and angle of incidence using a Gaussian distribution for its versatile applicability for mobile robots in mapping.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\UK9DGEAS\\Ahn et al. - 2019 - Analysis and Noise Modeling of the Intel RealSense.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\8FB669NG\\8768489.html},
  keywords = {axial noise,cameras,Cameras,d435,depth bias,distance inhomogeneity,distance measurement,form factor,Gaussian distribution,Image edge detection,image resolution,Intel RealSense D435,Intel RealSense RGB-D,lateral noise,legged locomotion,legged robots,mobile robots,Mobile robots,noise,noise modeling,nonoverlapping image regions,nonsystematic error,realsense,RGB data,robot vision,Robot vision systems,sensor,Sensor phenomena and characterization,stereo image processing,Webcams}
}

@article{alidoost_knowledge_2016,
  title = {Knowledge {{Based 3D Building Model Recognition Using Convolutional Neural Networks From Lidar}} and {{Aerial Imageries}}},
  author = {Alidoost, F. and Arefi, H.},
  year = {2016},
  volume = {XLI-B3},
  pages = {833--840},
  doi = {10.5194/isprs-archives-XLI-B3-833-2016},
  journal = {ISPRS - International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences}
}

@inproceedings{amdahl_validity_1967,
  title = {Validity of the Single Processor Approach to Achieving Large Scale Computing Capabilities},
  booktitle = {Proceedings of the {{April}} 18-20, 1967, Spring Joint Computer Conference},
  author = {Amdahl, Gene M.},
  year = {1967},
  month = apr,
  pages = {483--485},
  publisher = {{Association for Computing Machinery}},
  address = {{Atlantic City, New Jersey}},
  doi = {10.1145/1465482.1465560},
  abstract = {For over a decade prophets have voiced the contention that the organization of a single computer has reached its limits and that truly significant advances can be made only by interconnection of a multiplicity of computers in such a manner as to permit cooperative solution. Variously the proper direction has been pointed out as general purpose computers with a generalized interconnection of memories, or as specialized computers with geometrically related memory interconnections and controlled by one or more instruction streams.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\5FRI8MKU\\Amdahl - 1967 - Validity of the single processor approach to achie.pdf},
  isbn = {978-1-4503-7895-6},
  keywords = {parallelism},
  series = {{{AFIPS}} '67 ({{Spring}})}
}

@inproceedings{ancel_real-time_2017,
  title = {Real-Time {{Risk Assessment Framework}} for {{Unmanned Aircraft System}} ({{UAS}}) {{Traffic Management}} ({{UTM}})},
  booktitle = {17th {{AIAA Aviation Technology}}, {{Integration}}, and {{Operations Conference}}},
  author = {Ancel, Ersin and Capristan, Francisco M. and Foster, John V. and Condotta, Ryan C.},
  year = {2017},
  month = jun,
  publisher = {{American Institute of Aeronautics and Astronautics}},
  doi = {10.2514/6.2017-3273}
}

@inproceedings{assouline_building_2017,
  title = {Building Rooftop Classification Using Random Forests for Large-Scale {{PV}} Deployment},
  booktitle = {Earth {{Resources}} and {{Environmental Remote Sensing}}/{{GIS Applications VIII}}},
  author = {Assouline, Dan and Mohajeri, Nahid and Scartezzini, Jean-Louis},
  year = {2017},
  month = oct,
  volume = {10428},
  pages = {1042806},
  publisher = {{International Society for Optics and Photonics}},
  doi = {10.1117/12.2277692},
  abstract = {Large scale solar Photovoltaic (PV) deployment on existing building rooftops has proven to be one of the most efficient and viable sources of renewable energy in urban areas. As it usually requires a potential analysis over the area of interest, a crucial step is to estimate the geometric characteristics of the building rooftops. In this paper, we introduce a multi-layer machine learning methodology to classify 6 roof types, 9 aspect (azimuth) classes and 5 slope (tilt) classes for all building rooftops in Switzerland, using GIS processing. We train Random Forests (RF), an ensemble learning algorithm, to build the classifiers. We use (2 \&times; 2) [m\textsuperscript{2} ] LiDAR data (considering buildings and vegetation) to extract several rooftop features, and a generalised footprint polygon data to localize buildings. The roof classifier is trained and tested with 1252 labeled roofs from three different urban areas, namely Baden, Luzern, and Winterthur. The results for roof type classification show an average accuracy of 67\%. The aspect and slope classifiers are trained and tested with 11449 labeled roofs in the Zurich periphery area. The results for aspect and slope classification show different accuracies depending on the classes: while some classes are well identified, other under-represented classes remain challenging to detect.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\JTI6LA5F\\Assouline et al. - 2017 - Building rooftop classification using random fores.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\9XW44LZR\\12.2277692.html}
}

@article{atkins_emergency_2006,
  title = {Emergency {{Flight Planning Applied}} to {{Total Loss}} of {{Thrust}}},
  author = {Atkins, Ella M. and Portillo, Igor Alonso and Strube, Matthew J.},
  year = {2006},
  month = jul,
  volume = {43},
  pages = {1205--1216},
  publisher = {{American Institute of Aeronautics and Astronautics}},
  doi = {10.2514/1.18816},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\R7DU3GUD\\Atkins et al. - 2006 - Emergency Flight Planning Applied to Total Loss of.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\D9VEFGEC\\1.html},
  journal = {Journal of Aircraft},
  number = {4}
}

@article{balsa-barreiro_airborne_2012,
  title = {Airborne Light Detection and Ranging ({{LiDAR}}) Point Density Analysis},
  author = {{Balsa-Barreiro}, Jos{\'e} and Avariento, Joan P. and Lerma, Jos{\'e} Luis},
  year = {2012},
  volume = {7},
  pages = {3010--3019},
  doi = {10.5897/SRE12.278},
  abstract = {The point density is a preeminent parameter on airborne laser scanner surveys. It is not only related to accuracy but costs and savings. The lack of uniformity of the point density across the survey is well-known in the scientific community. This paper analyzes the behaviour of the point density derived by an oscillating mirror laser scanner on different single strips on flat bare ground in order to estimate a meaningful mean density value. The variation of the point density at both extreme ends of the oscillating mirror scan is meaningful. It will be demonstrated that excluding the extreme sectors across the strip corresponding to 1/8 of the swath width (12.5\% of the sampling area, half in each side) for the computation of the mean density value is enough to satisfy light detection and ranging (LiDAR) specifications for national level surveys.     ~     Key words:~Light detection and ranging (LiDAR), point density, point distribution.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\WBI6DVYU\\Balsa-Barreiro et al. - 2012 - Airborne light detection and ranging (LiDAR) point.pdf},
  journal = {Academic Journals}
}

@article{balsa-barreiro_generation_2018,
  title = {Generation of Visually Aesthetic and Detailed {{3D}} Models of Historical Cities by Using Laser Scanning and Digital Photogrammetry},
  author = {{Balsa-Barreiro}, Jos{\'e} and Fritsch, Dieter},
  year = {2018},
  month = mar,
  volume = {8},
  pages = {57--64},
  issn = {2212-0548},
  doi = {10.1016/j.daach.2017.12.001},
  abstract = {Historical cities (or towns) are inherently valuable for their uniqueness. Although reflecting the past, these cities offer significant opportunities. For this reason, it is important to know how to preserve them and assess their exploitation potential from different perspectives. An increased knowledge about them is continuously required and demanded. Three-dimensional (henceforth 3D) virtual models are an excellent way for introducing these cities to people. However, some particular characteristics derived from irregular urban structures and specific human dynamics in historical urban environments can constrain the use of some technologies for 3D data collection. This research paper proposes an own working methodology for the generation of 3D virtual models of historical cities. This methodology is based on the combined use of laser scanning and photogrammetric techniques, which complement each other. As a result, a 3D virtual model with high geometric accuracy and visual completeness is obtained and integrated into a web-based application. Resulting virtual models can be used for touristic promotion, navigation, urban planning, documentation and preservation of cultural heritage, etc.},
  journal = {Digital Applications in Archaeology and Cultural Heritage},
  keywords = {3D virtual city,Historical city,Laser scanning,Level of detail; photogrammetry,Photorealistic visualization},
  language = {en}
}

@inproceedings{bergelt_improving_2017,
  title = {Improving the Intrinsic Calibration of a {{Velodyne LiDAR}} Sensor},
  booktitle = {2017 {{IEEE SENSORS}}},
  author = {Bergelt, Rene and Khan, Owes and Hardt, Wolfram},
  year = {2017},
  month = oct,
  pages = {1--3},
  doi = {10.1109/ICSENS.2017.8234357},
  abstract = {LiDAR (Light detection and ranging) sensors are widely used in research and development. As such, they build the base for the evaluation of newly developed ADAS (Advanced Driver Assistance Systems) functions in the automotive field where they are used for ground truth establishment. However, the factory calibration provided for the sensors is not able to satisfy the high accuracy requirements by such applications. In this paper we propose a concept to easily improve the existing calibration of a Velodyne LiDAR sensor without the need for special calibration setups which can even be used to enhance already recorded data.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\M2ERDDAQ\\Bergelt et al. - 2017 - Improving the intrinsic calibration of a Velodyne .pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\JM2ZMHLH\\8234357.html},
  keywords = {ADAS,Advanced Driver Assistance Systems,automotive field,calibration,Calibration,crispness,driver information systems,ground truth establishment,intrinsic calibration,Laser radar,LiDAR,light detection-and-ranging sensors,Minimization,optical radar,optical sensors,Optimization,point cloud,Production facilities,Robot sensing systems,Three-dimensional displays,Velodyne LiDAR sensor}
}

@article{bernardini_ball-pivoting_1999,
  title = {The Ball-Pivoting Algorithm for Surface Reconstruction},
  author = {Bernardini, F. and Mittleman, J. and Rushmeier, H. and Silva, C. and Taubin, G.},
  year = {1999},
  month = oct,
  volume = {5},
  pages = {349--359},
  issn = {1941-0506},
  doi = {10.1109/2945.817351},
  abstract = {The Ball-Pivoting Algorithm (BPA) computes a triangle mesh interpolating a given point cloud. Typically, the points are surface samples acquired with multiple range scans of an object. The principle of the BPA is very simple: Three points form a triangle if a ball of a user-specified radius p touches them without containing any other point. Starting with a seed triangle, the ball pivots around an edge (i.e., it revolves around the edge while keeping in contact with the edge's endpoints) until it touches another point, forming another triangle. The process continues until all reachable edges have been tried, and then starts from another seed triangle, until all points have been considered. The process can then be repeated with a ball of larger radius to handle uneven sampling densities. We applied the BPA to datasets of millions of points representing actual scans of complex 3D objects. The relatively small amount of memory required by the BPA, its time efficiency, and the quality of the results obtained compare favorably with existing techniques.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\4CXCKY77\\Bernardini et al. - 1999 - The ball-pivoting algorithm for surface reconstruc.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\R6W5F39I\\817351.html},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  keywords = {ball-pivoting algorithm,computational geometry,Data acquisition,Geometrical optics,image reconstruction,Image reconstruction,mesh,mesh generation,Product design,Sampling methods,seed triangle,Shape,surface reconstruction,Surface reconstruction,surface samples,Three-dimensional displays,triangle mesh},
  number = {4}
}

@inproceedings{biswas_planar_2012,
  title = {Planar Polygon Extraction and Merging from Depth Images},
  booktitle = {2012 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}}},
  author = {Biswas, Joydeep and Veloso, Manuela},
  year = {2012},
  month = oct,
  pages = {3859--3864},
  issn = {2153-0858},
  doi = {10.1109/IROS.2012.6385841},
  abstract = {There has been considerable interest recently in building 3D maps of environments using inexpensive depth cameras like the Microsoft Kinect sensor. We exploit the fact that typical indoor scenes have an abundance of planar features by modeling environments as sets of plane polygons. To this end, we build upon the Fast Sampling Plane Filtering (FSPF) algorithm that extracts points belonging to local neighborhoods of planes from depth images, even in the presence of clutter. We introduce an algorithm that uses the FSPF-generated plane filtered point clouds to generate convex polygons from individual observed depth images. We then contribute an approach of merging these detected polygons across successive frames while accounting for a complete history of observed plane filtered points without explicitly maintaining a list of all observed points. The FSPF and polygon merging algorithms run in real time at full camera frame rates with low CPU requirements: in a real world indoor environment scene, the FSPF and polygon merging algorithms take 2.5 ms on average to process a single 640 \texttimes{} 480 depth image. We provide experimental results demonstrating the computational efficiency of the algorithm and the accuracy of the detected plane polygons by comparing with ground truth.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\V8VUWFXM\\Biswas and Veloso - 2012 - Planar polygon extraction and merging from depth i.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\8RDKQN64\\6385841.html},
  keywords = {3D map,cameras,Cameras,Clutter,convex polygon generation,depth camera,depth image,fast sampling plane filtering algorithm,feature extraction,Feature extraction,filtering theory,image sampling,Indoor environments,indoor scene,Merging,mesh,Microsoft Kinect sensor,planar polygon extraction,planar polygon merging,plane polygon,range images,sensors,Simultaneous localization and mapping,Solid modeling}
}

@misc{blanco_nanoflann_2014,
  title = {Nanoflann: A {{C}}++ Header-Only Fork of {{FLANN}}, a Library for {{Nearest Neighbor}} ({{NN}}) with {{KD}}-Trees},
  author = {Blanco, Jose Luis and Rai, Pranjal Kumar},
  year = {2014}
}

@article{borrmann_3d_2011,
  title = {The {{3D Hough Transform}} for Plane Detection in Point Clouds: {{A}} Review and a New Accumulator Design},
  shorttitle = {The {{3D Hough Transform}} for Plane Detection in Point Clouds},
  author = {Borrmann, Dorit and Elseberg, Jan and Lingemann, Kai and N{\"u}chter, Andreas},
  year = {2011},
  month = jun,
  volume = {2},
  pages = {3},
  issn = {2092-6731},
  doi = {10.1007/3DRes.02(2011)3},
  abstract = {The Hough Transform is a well-known method for detecting parameterized objects. It is the de facto standard for detecting lines and circles in 2-dimensional data sets. For 3D it has attained little attention so far. Even for the 2D case high computational costs have lead to the development of numerous variations for the Hough Transform. In this article we evaluate different variants of the Hough Transform with respect to their applicability to detect planes in 3D point clouds reliably. Apart from computational costs, the main problem is the representation of the accumulator. Usual implementations favor geometrical objects with certain parameters due to uneven sampling of the parameter space. We present a novel approach to design the accumulator focusing on achieving the same size for each cell and compare it to existing designs.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\BVWMZTQH\\Borrmann et al. - 2011 - The 3D Hough Transform for plane detection in poin.pdf},
  journal = {3D Research},
  language = {en},
  number = {2}
}

@article{canziani_analysis_2017,
  title = {An {{Analysis}} of {{Deep Neural Network Models}} for {{Practical Applications}}},
  author = {Canziani, Alfredo and Paszke, Adam and Culurciello, Eugenio},
  year = {2017},
  month = apr,
  abstract = {Since the emergence of Deep Neural Networks (DNNs) as a prominent technique in the field of computer vision, the ImageNet classification challenge has played a major role in advancing the state-of-the-art. While accuracy figures have steadily increased, the resource utilisation of winning models has not been properly taken into account. In this work, we present a comprehensive analysis of important metrics in practical applications: accuracy, memory footprint, parameters, operations count, inference time and power consumption. Key findings are: (1) power consumption is independent of batch size and architecture; (2) accuracy and inference time are in a hyperbolic relationship; (3) energy constraint is an upper bound on the maximum achievable accuracy and model complexity; (4) the number of operations is a reliable estimate of the inference time. We believe our analysis provides a compelling set of information that helps design and engineer efficient DNNs.},
  archivePrefix = {arXiv},
  eprint = {1605.07678},
  eprinttype = {arxiv},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\45QMWWWY\\Canziani et al. - 2017 - An Analysis of Deep Neural Network Models for Prac.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\PAAIIU2K\\1605.html},
  journal = {arXiv:1605.07678 [cs]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  note = {Comment: 7 pages, 10 figures, legend for Figure 2 got lost :/},
  primaryClass = {cs}
}

@article{cao_roof_2017,
  title = {Roof Plane Extraction from Airborne Lidar Point Clouds},
  author = {Cao, Rujun and Zhang, Yongjun and Liu, Xinyi and Zhao, Zongze},
  year = {2017},
  month = jun,
  volume = {38},
  pages = {3684--3703},
  issn = {0143-1161},
  doi = {10.1080/01431161.2017.1302112},
  abstract = {Planar patches are important primitives for polyhedral building models. One of the key challenges for successful reconstruction of three-dimensional (3D) building models from airborne lidar point clouds is achieving high quality recognition and segmentation of the roof planar points. Unfortunately, the current automatic extraction processes for planar surfaces continue to suffer from limitations such as sensitivity to the selection of seed points and the lack of computational efficiency. In order to address these drawbacks, a new fully automatic segmentation method is proposed in this article, which is capable of the following: (1) processing a roof point dataset with an arbitrary shape; (2) robustly selecting the seed points in a parameter space with reduced dimensions; and (3) segmenting the planar patches in a sub-dataset with similar attributes when region growing in the object space. The detection of seed points in the parameter space was improved by mapping the accumulator array to a 1D space. The range for region growing in the object space was reduced by an attribute similarity measure that split the roof dataset into candidate and non-candidate subsets. The experimental results confirmed that the proposed approach can extract planar patches of building roofs robustly and efficiently.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\AJRT4ZWR\\Cao et al. - 2017 - Roof plane extraction from airborne lidar point cl.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\23UFS5YS\\01431161.2017.html},
  journal = {International Journal of Remote Sensing},
  keywords = {plane,point cloud,roof},
  number = {12}
}

@incollection{castagno_automatic_2018,
  title = {Automatic {{Classification}} of {{Roof Shapes}} for {{Multicopter Emergency Landing Site Selection}}},
  booktitle = {2018 {{Aviation Technology}}, {{Integration}}, and {{Operations Conference}}},
  author = {Castagno, Jeremy and Atkins, Ella M.},
  year = {2018},
  month = jun,
  publisher = {{American Institute of Aeronautics and Astronautics}},
  doi = {10.2514/6.2018-3977},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\G9WIKSTP\\Castagno and Atkins - 2018 - Automatic Classification of Roof Shapes for Multic.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\5FHHSGAU\\6.html},
  series = {{{AIAA AVIATION Forum}}}
}

@inproceedings{castagno_comprehensive_2018,
  title = {Comprehensive {{Risk}}-Based {{Planning}} for {{Small Unmanned Aircraft System Rooftop Landing}}},
  booktitle = {2018 {{International Conference}} on {{Unmanned Aircraft Systems}} ({{ICUAS}})},
  author = {Castagno, Jeremy and Ochoa, Cosme and Atkins, Ella},
  year = {2018},
  month = jun,
  pages = {1031--1040},
  issn = {2575-7296},
  doi = {10.1109/ICUAS.2018.8453483},
  abstract = {The expected proliferation of Unmanned Aircraft Systems (UAS) has prompted many to question their safety and reliability, particularly in urban areas. Failures and anomalies can lead to the need for emergency landing, which in turn requires the UAS operator or autonomy to rapidly identify and evaluate the risks for possible landing sites and trajectories to reach these sites. This paper proposes a method to optimize the overall emergency landing site and flight path risks. Although sensors can scan an immediate area, no safe site might be observable in which case pre-processed data on more distant safe sites is required. For example, in urban regions, out of sight flat rooftops may pose less risk to people and property than landing in streets or sidewalks. This paper proposes the offline construction of a landing site database using a variety of public data sources, uniquely allowing for the assessment of risk associated with a rooftop landing. A real-time map-based planner is presented that demonstrates a novel trade-off between landing site risk and path risk and provides a heuristic to improve decision-making efficiency.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\EW67FTSP\\Castagno et al. - 2018 - Comprehensive Risk-based Planning for Small Unmann.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\KDKDKP3A\\8453483.html},
  keywords = {Aircraft,autonomous aerial vehicles,Buildings,case pre-processed data,comprehensive risk-based,Databases,decision making,distant safe sites,emergency landing site,expected proliferation,flight path risks,landing site database,path planning,path risk,Planning,possible landing sites,real-time map-based planner,risk management,safe site,Sensors,Shape,sight flat rooftops,Sociology,UAS,unmanned aircraft system rooftop landing,unmanned aircraft systems,urban areas,urban regions}
}

@misc{Castagno_Github_fastga,
  title = {Github - {{Fast Gaussian Sphere Accumulator}}},
  author = {Castagno, Jeremy},
  year = {2020},
  howpublished = {[Online] Available: \url{https://github.com/JeremyBYU/FastGaussianAccumulator}},
  note = {Accessed: 2020-06-05}
}

@misc{Castagno_Github_opf,
  title = {Github - {{Organized Point Filters}}},
  author = {Castagno, Jeremy},
  year = {2020},
  howpublished = {[Online] Available: \url{https://github.com/JeremyBYU/OrganizedPointFilters}},
  note = {Accessed: 2020-06-05}
}

@misc{Castagno_Github_Polylidar,
  title = {Github - {{Polylidar}}},
  author = {Castagno, Jeremy},
  year = {2020},
  howpublished = {[Online] Available: \url{https://github.com/JeremyBYU/polylidar}},
  note = {Accessed: 2019-01-05}
}

@misc{Castagno_Github_Polylidar_Synpeb,
  title = {Github - {{Polylidard3D}} and {{SynPEB}}},
  author = {Castagno, Jeremy},
  year = {2020},
  howpublished = {[Online] Available: \url{https://github.com/JeremyBYU/polylidar-plane-benchmark}},
  note = {Accessed: 2020-06-05}
}

@misc{Castagno_Github_Polylidar3D_Kitti,
  title = {Github - {{Polylidard3D}} and {{KITTI}}},
  author = {Castagno, Jeremy},
  year = {2020},
  howpublished = {[Online] Available: \url{https://github.com/JeremyBYU/polylidar-kitti}},
  note = {Accessed: 2020-06-05}
}

@misc{Castagno_Github_Polylidar3D_RealSense,
  title = {Github - {{Polylidar3D}} with {{RealSense}}},
  author = {Castagno, Jeremy},
  year = {2020},
  howpublished = {[Online] Available: \url{https://github.com/JeremyBYU/polylidar-realsense}},
  note = {Accessed: 2020-06-05}
}

@article{castagno_multi-uav_nodate,
  title = {Multi-{{UAV Wildire Boundary Estimation}} Using a {{Semantic Segmentation Neural Network}}},
  author = {Castagno, Jeremy and Romano, Matthew and Kuevor, Prince and Atkins, Ella},
  journal = {Journal of Aerospace Information Systems},
  note = {Submitted and under review}
}

@article{castagno_polylidar_2020,
  title = {Polylidar - {{Polygons From Triangular Meshes}}},
  author = {Castagno, Jeremy and Atkins, Ella},
  year = {2020},
  month = jul,
  volume = {5},
  pages = {4634--4641},
  issn = {2377-3766},
  doi = {10.1109/LRA.2020.3002212},
  abstract = {This letter presents Polylidar, an efficient algorithm to extract non-convex polygons from 2D point sets, including interior holes. Plane segmented point clouds can be input into Polylidar to extract their polygonal counterpart, thereby reducing map size and improving visualization. The algorithm begins by triangulating the point set and filtering triangles by user configurable parameters such as triangle edge length. Next, connected triangles are extracted into triangular mesh regions representing the shape of the point set. Finally each region is converted to a polygon through a novel boundary following method which accounts for holes. Real-world and synthetic benchmarks are presented to comparatively evaluate Polylidar speed and accuracy. Results show comparable accuracy and more than four times speedup compared to other concave polygon extraction methods.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\TG4K383P\\Castagno and Atkins - 2020 - Polylidar - Polygons From Triangular Meshes.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\BP5PTJD8\\9117017.html},
  journal = {IEEE Robotics and Automation Letters},
  keywords = {2D point sets,Aerial systems: perception and autonomy,Benchmark testing,boundary following method,computational geometry,concave polygon extraction methods,connected triangles,Data mining,Data structures,data visualisation,improving visualization,Indexes,interior holes,map size,mesh generation,nonconvex polygons,point clouds,polygonal counterpart,polylidar,reactive and sensor-based planning,Shape,Three-dimensional displays,triangle edge length,triangular mesh regions,triangular meshes,Two dimensional displays,user configurable parameters},
  number = {3}
}

@article{castagno_roof_2018,
  title = {Roof {{Shape Classification}} from {{LiDAR}} and {{Satellite Image Data Fusion Using Supervised Learning}}},
  author = {Castagno, Jeremy and Atkins, Ella},
  year = {2018},
  month = nov,
  volume = {18},
  pages = {3960},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  doi = {10.3390/s18113960},
  abstract = {Geographic information systems (GIS) provide accurate maps of terrain, roads, waterways, and building footprints and heights. Aircraft, particularly small unmanned aircraft systems (UAS), can exploit this and additional information such as building roof structure to improve navigation accuracy and safely perform contingency landings particularly in urban regions. However, building roof structure is not fully provided in maps. This paper proposes a method to automatically label building roof shape from publicly available GIS data. Satellite imagery and airborne LiDAR data are processed and manually labeled to create a diverse annotated roof image dataset for small to large urban cities. Multiple convolutional neural network (CNN) architectures are trained and tested, with the best performing networks providing a condensed feature set for support vector machine and decision tree classifiers. Satellite image and LiDAR data fusion is shown to provide greater classification accuracy than using either data type alone. Model confidence thresholds are adjusted leading to significant increases in models precision. Networks trained from roof data in Witten, Germany and Manhattan (New York City) are evaluated on independent data from these cities and Ann Arbor, Michigan.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\IW93TSG4\\Castagno and Atkins - 2018 - Roof Shape Classification from LiDAR and Satellite.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\JJSQN3DG\\3960.html},
  journal = {Sensors},
  keywords = {drones,geographical information system (GIS),LiDAR,machine learning,machine vision,maps,safety,unmanned aircraft systems (UAS)},
  language = {en},
  number = {11}
}

@misc{chollet_keras_2015,
  title = {Keras},
  author = {Chollet, Francois and others},
  year = {2015},
  publisher = {{GitHub}}
}

@article{cohen_gauge_2019,
  title = {Gauge {{Equivariant Convolutional Networks}} and the {{Icosahedral CNN}}},
  author = {Cohen, Taco S. and Weiler, Maurice and Kicanaoglu, Berkay and Welling, Max},
  year = {2019},
  month = may,
  abstract = {The principle of equivariance to symmetry transformations enables a theoretically grounded approach to neural network architecture design. Equivariant networks have shown excellent performance and data efficiency on vision and medical imaging problems that exhibit symmetries. Here we show how this principle can be extended beyond global symmetries to local gauge transformations. This enables the development of a very general class of convolutional neural networks on manifolds that depend only on the intrinsic geometry, and which includes many popular methods from equivariant and geometric deep learning.},
  archivePrefix = {arXiv},
  eprint = {1902.04615},
  eprinttype = {arxiv},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\ECEJBS7C\\Cohen et al. - 2019 - Gauge Equivariant Convolutional Networks and the I.pdf},
  journal = {arXiv:1902.04615 [cs, stat]},
  keywords = {Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computing,Statistics - Machine Learning},
  language = {en},
  note = {Comment: Proceedings of the International Conference on Machine Learning (ICML), 2019},
  primaryClass = {cs, stat}
}

@article{cohen_spherical_2018-1,
  title = {Spherical {{CNNs}}},
  author = {Cohen, Taco S. and Geiger, Mario and Koehler, Jonas and Welling, Max},
  year = {2018},
  month = feb,
  abstract = {Convolutional Neural Networks (CNNs) have become the method of choice for learning problems involving 2D planar images. However, a number of problems of recent interest have created a demand for models that can analyze spherical images. Examples include omnidirectional vision for drones, robots, and autonomous cars, molecular regression problems, and global weather and climate modelling. A naive application of convolutional networks to a planar projection of the spherical signal is destined to fail, because the space-varying distortions introduced by such a projection will make translational weight sharing ineffective. In this paper we introduce the building blocks for constructing spherical CNNs. We propose a definition for the spherical cross-correlation that is both expressive and rotation-equivariant. The spherical correlation satisfies a generalized Fourier theorem, which allows us to compute it efficiently using a generalized (non-commutative) Fast Fourier Transform (FFT) algorithm. We demonstrate the computational efficiency, numerical accuracy, and effectiveness of spherical CNNs applied to 3D model recognition and atomization energy regression.},
  archivePrefix = {arXiv},
  eprint = {1801.10130},
  eprinttype = {arxiv},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\JKS798L3\\Cohen et al. - 2018 - Spherical CNNs.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\FX52WH4U\\1801.html},
  journal = {arXiv:1801.10130 [cs, stat]},
  keywords = {cnn,Computer Science - Machine Learning,harmonics,Statistics - Machine Learning},
  note = {Comment: Proceedings of the 6th International Conference on Learning Representations (ICLR), 2018},
  primaryClass = {cs, stat}
}

@article{coombes_reachability_2014,
  title = {Reachability {{Analysis}} of {{Landing Sites}} for {{Forced Landing}} of a {{UAS}}},
  author = {Coombes, Matthew and Chen, Wen-Hua and Render, Peter},
  year = {2014},
  month = jan,
  volume = {73},
  pages = {635--653},
  issn = {1573-0409},
  doi = {10.1007/s10846-013-9920-9},
  abstract = {This paper details a method to ascertain the reachability of known emergency landing sites for any fixed wing aircraft in a forced landing situation. With a knowledge of the aircraft's state and parameters, as well as a known wind profile, the area of maximum glide range can be calculated using aircraft equations of motion for gliding flight. A landing descent circuit technique used by human pilots carrying out forced landings called high key low key is employed to account for the extra glide distance required for an approach and landing. By combining maximum glide range analysis with the descent circuit, all the reachable landing sites can be determined. X-Plane flight simulator is used to demonstrate and validate the techniques presented.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\9L6S2FFI\\Coombes et al. - 2014 - Reachability Analysis of Landing Sites for Forced .pdf},
  journal = {Journal of Intelligent \& Robotic Systems},
  language = {en},
  number = {1}
}

@article{dagum_openmp_1998,
  title = {{{OpenMP}}: An Industry Standard {{API}} for Shared-Memory Programming},
  author = {Dagum, Leonardo and Menon, Ramesh},
  year = {1998},
  volume = {5},
  pages = {46--55},
  publisher = {{IEEE}},
  journal = {Computational Science \& Engineering, IEEE},
  number = {1}
}

@article{de_berg_delaunay_2008,
  title = {Delaunay {{Triangulations}}: {{Height Interpolation}}},
  author = {{de Berg}, Mark and Cheong, Otfried and {van Kreveld}, Marc and Overmars, Mark},
  year = {2008},
  pages = {191--218},
  journal = {Computational Geometry: Algorithms and Applications}
}

@techreport{degarmo_issues_2013,
  title = {Issues {{Concerning Integration}} of {{Unmanned Aerial Vehicles}} in {{Civil Airspace}}},
  author = {DeGarmo, Matthew T.},
  year = {2013},
  month = sep,
  institution = {{The Mitre Corporation}},
  abstract = {Interest in Unmanned Aerial Vehicles (UAVs) is growing worldwide and several efforts are underway to integrate UAV operations routinely and safely into civil airspace. Currently, UAV operations are confined to special-use airspace or are limited in their access, for safety reasons, by a restrictive authorization process. This document provides a context of UAV developments, describes current initiatives, and frames and assesses the issues associated with the integration of UAVs in civil airspace.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\KKS8JB6F\\DeGarmo - 2013 - Issues Concerning Integration of Unmanned Aerial V.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\67PYWZ2P\\issues-concerning-integration-of-unmanned-aerial-vehicles-in-civil-airspace.html},
  language = {en}
}

@article{desaraju_vision-based_2015,
  title = {Vision-Based Landing Site Evaluation and Informed Optimal Trajectory Generation toward Autonomous Rooftop Landing},
  author = {Desaraju, Vishnu R. and Michael, Nathan and Humenberger, Martin and Brockers, Roland and Weiss, Stephan and Nash, Jeremy and Matthies, Larry},
  year = {2015},
  month = oct,
  volume = {39},
  pages = {445--463},
  issn = {1573-7527},
  doi = {10.1007/s10514-015-9456-x},
  abstract = {Autonomous landing is an essential function for micro air vehicles (MAVs) for many scenarios. We pursue an active perception strategy that enables MAVs with limited onboard sensing and processing capabilities to concurrently assess feasible rooftop landing sites with a vision-based perception system while generating trajectories that balance continued landing site assessment and the requirement to provide visual monitoring of an interest point. The contributions of the work are twofold: (1) a perception system that employs a dense motion stereo approach that determines the 3D model of the captured scene without the need of geo-referenced images, scene geometry constraints, or external navigation aids; and (2) an online trajectory generation approach that balances the need to concurrently explore available rooftop vantages of an interest point while ensuring confidence in the landing site suitability by considering the impact of landing site uncertainty as assessed by the perception system. Simulation and experimental evaluation of the performance of the perception and trajectory generation methodologies are analyzed independently and jointly in order to establish the efficacy and robustness of the proposed approach.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\K9DI52ME\\Desaraju et al. - 2015 - Vision-based landing site evaluation and informed .pdf},
  journal = {Autonomous Robots},
  language = {en},
  number = {3}
}

@article{di_donato_evaluating_2017,
  title = {Evaluating {{Risk}} to {{People}} and {{Property}} for {{Aircraft Emergency Landing Planning}}},
  author = {Di Donato, Pedro F. A. and Atkins, Ella M.},
  year = {2017},
  volume = {14},
  pages = {259--278},
  publisher = {{American Institute of Aeronautics and Astronautics}},
  doi = {10.2514/1.I010513},
  abstract = {General aviation and small unmanned aircraft systems are less redundant, may be less thoroughly tested, and are flown at lower cruise altitudes than commercial aviation counterparts. These factors result in a higher probability of a forced or emergency landing scenario. Currently, general aviation relies on the pilot to select a landing site and plan a trajectory, even though workload in an emergency is typically high, and decisions must be made rapidly. Although sensors can provide local real-time information, awareness of more distant or occluded regions requires database and/or offboard data sources. This paper considers different data sources and how to process these data to inform an emergency landing planner regarding risks posed to property, people on the ground, and the aircraft itself. Detailed terrain data are used for selection of candidate emergency landing sites. Mobile phone activity is evaluated as a means of real-time occupancy estimation. Occupancy estimates are combined with population census data to estimate emergency landing risk to people on the ground. Openly available databases are identified and mined as part of an emergency landing planning case study.},
  annotation = {\_eprint: https://doi.org/10.2514/1.I010513},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\2QUG9GZQ\\Di Donato and Atkins - 2017 - Evaluating Risk to People and Property for Aircraf.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\CPKWQ2PE\\1.html;C\:\\Users\\Jeremy\\Zotero\\storage\\RP5L8A6V\\1.html},
  journal = {Journal of Aerospace Information Systems},
  number = {5}
}

@article{dmowska_high_2017-1,
  title = {A {{High Resolution Population Grid}} for the {{Conterminous United States}}: {{The}} 2010 Edition},
  shorttitle = {A High Resolution Population Grid for the Conterminous {{United States}}},
  author = {Dmowska, Anna and Stepinski, Tomasz F.},
  year = {2017},
  month = jan,
  volume = {61},
  pages = {13--23},
  issn = {0198-9715},
  doi = {10.1016/j.compenvurbsys.2016.08.006},
  abstract = {Readily available high resolution data on population distribution is an important resource for monitoring human-environment interactions and for supporting planning and management decisions. Using a grid that approximates population density over the entire country seems like the most practical approach to exploring and distributing detailed population data but instead data based on census aggregation units is still the most widely used method. In this paper we describe the construction of 30m resolution grid representing the distribution of population in 2010 over the entire conterminous United States. The grid is computed using 2010 U.S. Census block level population counts disaggregated by a dasymetric model that uses land cover (2011 NLCD) and land use (2010 NLUD) as ancillary data. Detailed descriptions of the ancillary data and dasymetric model are given. Methods of computing the grid are presented followed by an extensive assessment of model accuracy. Overall the expected value for relative error of the model is 44\% which is at the lower limit of errors reported for other continental-sized, high resolution population grids. We also offer a more specific error estimate for areas with specified value of population density. Using two example areas, one highly urbanized and another rural, we demonstrate the advantages of using the gridded population data over the census block-based data. Our 30m population grid is available for online exploration and for download from the custom-made GeoWeb application SocScape at http://sil.uc.edu.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\QHE3GZ7C\\Dmowska and Stepinski - 2017 - A high resolution population grid for the contermi.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\6D5E57V6\\S0198971516301983.html},
  journal = {Computers, Environment and Urban Systems},
  keywords = {census,Census,Dasymetric modeling,Gridded population data,Land use,NLCD},
  language = {en}
}

@article{douglas_algorithms_1973,
  title = {Algorithms for the Reduction of the Number of Points Required to Represent a Digitized Line or Its Caricature},
  author = {Douglas, David H and Peucker, Thomas K},
  year = {1973},
  month = dec,
  volume = {10},
  pages = {112--122},
  publisher = {{University of Toronto Press}},
  issn = {0317-7173},
  doi = {10.3138/FM57-6770-U75U-7727},
  abstract = {All digitizing methods, as a general rule, record lines with far more data than is necessary for accurate graphic reproduction or for computer analysis. Two algorithms to reduce the number of points required to represent the line and, if desired, produce caricatures, are presented and compared with the most promising methods so far suggested. Line reduction will form a major part of automated generalization. R\`egle g\'en\'erale, les m\'ethodes num\'eriques enregistrent des lignes avec beaucoup plus de donn\'ees qu'il n'est n\'ecessaire \`a la reproduction graphique pr\'ecise ou \`a la recherche par ordinateur. L'auteur pr\'esente deux algorithmes pour r\'eduire le nombre de points n\'ecessaires pour repr\'esenter la ligne et produire des caricatures si d\'esir\'e, et les compare aux m\'ethodes les plus prometteuses sugg\'er\'ees jusqu'ici. La r\'eduction de la ligne constituera une partie importante de la g\'en\'eralisation automatique.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\AF99SDBI\\Douglas and Peucker - 1973 - Algorithms for the reduction of the number of poin.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\PZMFZQP4\\FM57-6770-U75U-7727.html},
  journal = {Cartographica: The International Journal for Geographic Information and Geovisualization},
  number = {2}
}

@article{duckham_efficient_2008,
  title = {Efficient Generation of Simple Polygons for Characterizing the Shape of a Set of Points in the Plane},
  author = {Duckham, Matt and Kulik, Lars and Worboys, Mike and Galton, Antony},
  year = {2008},
  month = oct,
  volume = {41},
  pages = {3224--3236},
  issn = {0031-3203},
  doi = {10.1016/j.patcog.2008.03.023},
  abstract = {This paper presents a simple, flexible, and efficient algorithm for constructing a possibly non-convex, simple polygon that characterizes the shape of a set of input points in the plane, termed a characteristic shape. The algorithm is based on the Delaunay triangulation of the points. The shape produced by the algorithm is controlled by a single normalized parameter, which can be used to generate a finite, totally ordered family of related characteristic shapes, varying between the convex hull at one extreme and a uniquely defined shape with minimum area. An optimal O(nlogn) algorithm for computing the shapes is presented. Characteristic shapes possess a number of desirable properties, and the paper includes an empirical investigation of the shapes produced by the algorithm. This investigation provides experimental evidence that with appropriate parameterization the algorithm is able to accurately characterize the shape of a wide range of different point distributions and densities. The experiments detail the effects of changing parameter values and provide an indication of some ``good'' parameter values to use in certain circumstances.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\4UFC4IP5\\Duckham et al. - 2008 - Efficient generation of simple polygons for charac.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\RNIN7HWG\\S0031320308001180.html},
  journal = {Pattern Recognition},
  keywords = {Alpha shape,Cartography,Convex hull,GIS,Shape analysis},
  language = {en},
  number = {10}
}

@article{edelsbrunner_shape_1983,
  title = {On the Shape of a Set of Points in the Plane},
  author = {Edelsbrunner, H. and Kirkpatrick, D. and Seidel, R.},
  year = {1983},
  month = jul,
  volume = {29},
  pages = {551--559},
  issn = {1557-9654},
  doi = {10.1109/TIT.1983.1056714},
  abstract = {A generalization of the convex hull of a finite set of points in the plane is introduced and analyzed. This generalization leads to a family of straight-line graphs, "\textbackslash alpha-shapes," which seem to capture the intuitive notions of "fine shape" and "crude shape" of point sets. It is shown that a-shapes are subgraphs of the closest point or furthest point Delaunay triangulation. Relying on this result an optimalO(n \textbackslash log n)algorithm that constructs\textbackslash alpha-shapes is developed.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\2FZWBPUC\\Edelsbrunner et al. - 1983 - On the shape of a set of points in the plane.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\93J7DGWY\\1056714.html},
  journal = {IEEE Transactions on Information Theory},
  keywords = {Geometry,Image analysis; shape,Image shape analysis},
  number = {4}
}

@misc{federal_aviation_administration_code_2016,
  title = {Code of {{Federal Regulations}} (14 {{CFR}}) {{Part}} 107.},
  author = {{Federal Aviation Administration}},
  year = {2016},
  publisher = {{FAA Washington, DC}}
}

@book{federal_aviation_administration_unmanned_2019,
  title = {Unmanned {{Aircraft Systems FY2019}}},
  author = {Federal Aviation Administration},
  year = {2019},
  publisher = {{FAA Washington, DC}},
  note = {Accessed: 2019-09-10},
  series = {The {{FAA Aerospace Forecast}}}
}

@inproceedings{feng_fast_2014,
  title = {Fast Plane Extraction in Organized Point Clouds Using Agglomerative Hierarchical Clustering},
  booktitle = {2014 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Feng, Chen and Taguchi, Yuichi and Kamat, Vineet R.},
  year = {2014},
  month = may,
  pages = {6218--6225},
  issn = {1050-4729},
  doi = {10.1109/ICRA.2014.6907776},
  abstract = {Real-time plane extraction in 3D point clouds is crucial to many robotics applications. We present a novel algorithm for reliably detecting multiple planes in real time in organized point clouds obtained from devices such as Kinect sensors. By uniformly dividing such a point cloud into non-overlapping groups of points in the image space, we first construct a graph whose node and edge represent a group of points and their neighborhood respectively. We then perform an agglomerative hierarchical clustering on this graph to systematically merge nodes belonging to the same plane until the plane fitting mean squared error exceeds a threshold. Finally we refine the extracted planes using pixel-wise region growing. Our experiments demonstrate that the proposed algorithm can reliably detect all major planes in the scene at a frame rate of more than 35Hz for 640\texttimes 480 point clouds, which to the best of our knowledge is much faster than state-of-the-art algorithms.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\BGHHTBNB\\Feng et al. - 2014 - Fast plane extraction in organized point clouds us.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\7NH33W54\\6907776.html},
  keywords = {3D point clouds,agglomerative hierarchical clustering,clustering,Clustering algorithms,computer graphics,feature extraction,Image segmentation,image sensors,image space,Kinect sensors,mean square error methods,Merging,nonoverlapping groups,object detection,pattern clustering,pixel-wise region growing,plane,plane fitting mean squared error,planes detection,real-time plane extraction,Real-time systems,robotics applications,Robots,Sensors,Three-dimensional displays}
}

@inproceedings{forster_continuous_2015,
  title = {Continuous On-Board Monocular-Vision-Based Elevation Mapping Applied to Autonomous Landing of Micro Aerial Vehicles},
  booktitle = {2015 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Forster, C. and Faessler, M. and Fontana, F. and Werlberger, M. and Scaramuzza, D.},
  year = {2015},
  month = may,
  pages = {111--118},
  issn = {1050-4729},
  doi = {10.1109/ICRA.2015.7138988},
  abstract = {In this paper, we propose a resource-efficient system for real-time 3D terrain reconstruction and landing-spot detection for micro aerial vehicles. The system runs on an on-board smartphone processor and requires only the input of a single downlooking camera and an inertial measurement unit. We generate a two-dimensional elevation map that is probabilistic, of fixed size, and robot-centric, thus, always covering the area immediately underneath the robot. The elevation map is continuously updated at a rate of 1 Hz with depth maps that are triangulated from multiple views using recursive Bayesian estimation. To highlight the usefulness of the proposed mapping framework for autonomous navigation of micro aerial vehicles, we successfully demonstrate fully autonomous landing including landing-spot detection in real-world experiments.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\U3ZCRU42\\Forster et al. - 2015 - Continuous on-board monocular-vision-based elevati.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\C3RGG23L\\7138988.html},
  keywords = {aerospace navigation,autonomous aerial vehicles,autonomous micro aerial vehicle landing,autonomous micro aerial vehicle navigation,Bayes methods,cameras,Cameras,continuous onboard monocular-vision-based elevation mapping,depth maps,Estimation,frequency 1 Hz,image reconstruction,inertial measurement unit,landing-spot detection,object detection,on-board smartphone processor,real-time 3D terrain reconstruction,Real-time systems,recursive Bayesian estimation,recursive estimation,resource-efficient system,robot vision,Robot vision systems,single downlooking camera,Three-dimensional displays,two-dimensional elevation map,Uncertainty}
}

@article{freeman_assessing_2013,
  title = {Assessing Bimodality to Detect the Presence of a Dual Cognitive Process},
  author = {Freeman, Jonathan B. and Dale, Rick},
  year = {2013},
  month = mar,
  volume = {45},
  pages = {83--97},
  issn = {1554-3528},
  doi = {10.3758/s13428-012-0225-x},
  abstract = {Researchers have long sought to distinguish between single-process and dual-process cognitive phenomena, using responses such as reaction times and, more recently, hand movements. Analysis of a response distribution's modality has been crucial in detecting the presence of dual processes, because they tend to introduce bimodal features. Rarely, however, have bimodality measures been systematically evaluated. We carried out tests of readily available bimodality measures that any researcher may easily employ: the bimodality coefficient (BC), Hartigan's dip statistic (HDS), and the difference in Akaike's information criterion between one-component and two-component distribution models (AICdiff). We simulated distributions containing two response populations and examined the influences of (1) the distances between populations, (2) proportions of responses, (3) the amount of positive skew present, and (4) sample size. Distance always had a stronger effect than did proportion, and the effects of proportion greatly differed across the measures. Skew biased the measures by increasing bimodality detection, in some cases leading to anomalous interactive effects. BC and HDS were generally convergent, but a number of important discrepancies were found. AICdiff was extremely sensitive to bimodality and identified nearly all distributions as bimodal. However, all measures served to detect the presence of bimodality in comparison to unimodal simulations. We provide a validation with experimental data, discuss methodological and theoretical implications, and make recommendations regarding the choice of analysis.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\6I4F9AW8\\Freeman and Dale - 2013 - Assessing bimodality to detect the presence of a d.pdf},
  journal = {Behavior Research Methods},
  language = {en},
  number = {1}
}

@misc{furieri_spatialite_2017,
  title = {Spatialite},
  author = {Furieri, A.},
  year = {2017},
  howpublished = {[Online] Available: \url{https://www.gaia-gis.it/fossil/libspatialite/index}},
  note = {Visited on 2017-01-14}
}

@article{garcia-castellanos_poles_2007,
  title = {Poles of Inaccessibility: {{A}} Calculation Algorithm for the Remotest Places on Earth},
  shorttitle = {Poles of Inaccessibility},
  author = {{Garcia-Castellanos}, Daniel and Lombardo, Umberto},
  year = {2007},
  month = sep,
  volume = {123},
  pages = {227--233},
  publisher = {{Routledge}},
  issn = {1470-2541},
  doi = {10.1080/14702540801897809},
  abstract = {An algorithm is presented to calculate the point on the surface of a sphere maximising the great-circle distance to a given spherical polygon. This is used to calculate the spots furthest from the sea in major land masses, also known as Poles of Inaccessibility (PIA), a concept that has raised the interest of explorers. For the Eurasian pole of inaccessibility (EPIA), the results reveal a misplacement in previous calculations ranging from 156 to 435 km. Although in general there is only one pole for a given coastline, the present calculations show that, within the error inherent to the definition of the coastline, two locations are candidates for EPIA, one equidistant from Gulf of Ob, Gulf of Bengal and Arabian Sea, and the other equidistant from Gulf of Ob, Gulf of Bengal and Gulf of Bohai, both poles being located in the north westernmost Chinese province of Xinjiang. The distance to the sea at these locations is 2510 and 2514 km respectively, about 120 km closer than generally thought.},
  annotation = {\_eprint: https://doi.org/10.1080/14702540801897809},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\4LAAKU5H\\Garcia-Castellanos and Lombardo - 2007 - Poles of inaccessibility A calculation algorithm .pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\LWQR4MUL\\14702540801897809.html},
  journal = {Scottish Geographical Journal},
  keywords = {computer method,Distance to sea},
  number = {3}
}

@article{geiger_vision_2013,
  title = {Vision Meets {{Robotics}}: {{The KITTI Dataset}}},
  author = {Geiger, Andreas and Lenz, Philip and Stiller, Christoph and Urtasun, Raquel},
  year = {2013},
  volume = {32},
  pages = {1231--1237},
  doi = {10.1177/0278364913491297},
  journal = {International Journal of Robotics Research (IJRR)},
  number = {11}
}

@misc{gillies_github_2020,
  title = {Github - {{Shapely}}: {{Manipulation}} and {{Analysis}} of {{Geometric Objects}}},
  author = {Gillies, Sean and others},
  year = {2020},
  note = {Accessed: 2020-06-05}
}

@misc{google_s2_2020,
  title = {S2 {{Geometry}}},
  author = {{Google}},
  year = {2020},
  note = {Accessed: 2020-06-05}
}

@misc{graham_random_2014,
  title = {Random {{Points}}: {{How Dense Are You}}, {{Anyway}}?},
  shorttitle = {Random {{Points}}},
  author = {Graham, Lewis},
  year = {2014},
  month = jul,
  abstract = {A 1.023Mb PDF of this article as it appeared in the magazine complete with images is available by clicking HERE You may be...},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\62X8883R\\random-points-how-dense-are-you-anyway.html},
  howpublished = {http://localhost:10018/2014/07/05/random-points-how-dense-are-you-anyway/},
  journal = {LIDAR Magazine},
  keywords = {lidar},
  language = {en-US}
}

@article{haala_update_2010,
  title = {An Update on Automatic {{3D}} Building Reconstruction},
  author = {Haala, Norbert and Kada, Martin},
  year = {2010},
  month = nov,
  volume = {65},
  pages = {570--580},
  issn = {0924-2716},
  doi = {10.1016/j.isprsjprs.2010.09.006},
  abstract = {The development of tools for the generation of 3D city models started almost two decades ago. From the beginning, fully automatic reconstruction systems were envisioned to fulfil the need for efficient data collection. However, research on automatic city modelling is still a very active area. The paper will review a number of current approaches in order to comprehensively elaborate the state of the art of reconstruction methods and their respective principles. Originally, automatic city modelling only aimed at polyhedral building objects, which mainly reflects the respective roof shapes and building footprints. For this purpose, airborne images or laser scans are used. In addition to these developments, the paper will also review current approaches for the generation of more detailed facade geometries from terrestrial data collection.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\EARXAH6F\\Haala and Kada - 2010 - An update on automatic 3D building reconstruction.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\74WWET3Z\\S0924271610000894.html},
  journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
  keywords = {Automation,Building,Reconstruction,Three-dimensional,Urban},
  language = {en},
  number = {6},
  series = {{{ISPRS Centenary Celebration Issue}}}
}

@article{hartigan_algorithm_1985,
  title = {Algorithm {{AS}} 217: {{Computation}} of the Dip Statistic to Test for Unimodality},
  author = {Hartigan, PM},
  year = {1985},
  volume = {34},
  pages = {320--325},
  publisher = {{JSTOR}},
  journal = {Journal of the Royal Statistical Society. Series C (Applied Statistics)},
  number = {3}
}

@inproceedings{he_deep_2016,
  title = {Deep {{Residual Learning}} for {{Image Recognition}}},
  booktitle = {2016 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {He, K. and Zhang, X. and Ren, S. and Sun, J.},
  year = {2016},
  month = jun,
  pages = {770--778},
  issn = {1063-6919},
  doi = {10.1109/CVPR.2016.90},
  abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers - 8\texttimes{} deeper than VGG nets [40] but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions1, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\8MY688UV\\He et al. - 2016 - Deep Residual Learning for Image Recognition.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\ZZ4E5ACP\\7780459.html},
  keywords = {CIFAR-10,COCO object detection dataset,COCO segmentation,Complexity theory,deep residual learning,deep residual nets,deeper neural network training,Degradation,ILSVRC \& COCO 2015 competitions,ILSVRC 2015 classification task,image classification,image recognition,Image recognition,Image segmentation,ImageNet dataset,ImageNet localization,ImageNet test set,learning (artificial intelligence),neural nets,Neural networks,object detection,residual function learning,residual nets,Training,VGG nets,visual recognition tasks,Visualization}
}

@article{herring_opengis_2006-1,
  title = {{{OpenGIS}} Implementation Specification for Geographic Information-{{Simple}} Feature Access- {{Part}} 1: {{Common}} Architecture},
  author = {Herring, John R},
  year = {2006},
  pages = {95},
  journal = {Open Geospatial Consortium}
}

@inproceedings{himmelsbach_fast_2010,
  title = {Fast Segmentation of {{3D}} Point Clouds for Ground Vehicles},
  booktitle = {2010 {{IEEE Intelligent Vehicles Symposium}}},
  author = {Himmelsbach, M. and v Hundelshausen, F. and Wuensche, H.-},
  year = {2010},
  month = jun,
  pages = {560--565},
  issn = {1931-0587},
  doi = {10.1109/IVS.2010.5548059},
  abstract = {This paper describes a fast method for segmentation of large-size long-range 3D point clouds that especially lends itself for later classification of objects. Our approach is targeted at high-speed autonomous ground robot mobility, so real-time performance of the segmentation method plays a critical role. This is especially true as segmentation is considered only a necessary preliminary for the more important task of object classification that is itself computationally very demanding. Efficiency is achieved in our approach by splitting the segmentation problem into two simpler subproblems of lower complexity: local ground plane estimation followed by fast 2D connected components labeling. The method's performance is evaluated on real data acquired in different outdoor scenes, and the results are compared to those of existing methods. We show that our method requires less runtime while at the same time yielding segmentation results that are better suited for later classification of the identified objects.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\XN5Z9RST\\Himmelsbach et al. - 2010 - Fast segmentation of 3D point clouds for ground ve.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\82CP8Q2S\\5548059.html},
  keywords = {3D point clouds,autonomous ground robot mobility,Clouds,computational complexity,computer graphics,fast segmentation,ground plane estimation,ground vehicles,image classification,image segmentation,Land vehicles,Laser radar,Layout,lower complexity,mobile robots,Mobile robots,object classification,Object detection,Real time systems,Remotely operated vehicles,road vehicles,Robot sensing systems,Sensor phenomena and characterization,traffic engineering computing}
}

@misc{hipp_sqlite_2020,
  title = {{{SQLite}} ({{Version}} 3.28) {{SQLite Development Team}}},
  author = {Hipp, D. R. and Kennedy, D. and Mistachkin, J.},
  year = {2020},
  howpublished = {[Online] Available: \url{https://www.sqlite.org/index.html}},
  note = {Visited on 2020-06-14}
}

@article{hoover_experimental_1996,
  title = {An Experimental Comparison of Range Image Segmentation Algorithms},
  author = {Hoover, A. and {Jean-Baptiste}, G. and Jiang, X. and Flynn, P.J. and Bunke, H. and Goldgof, D.B. and Bowyer, K. and Eggert, D.W. and Fitzgibbon, A. and Fisher, R.B.},
  year = {1996},
  month = jul,
  volume = {18},
  pages = {673--689},
  issn = {1939-3539},
  doi = {10.1109/34.506791},
  abstract = {A methodology for evaluating range image segmentation algorithms is proposed. This methodology involves (1) a common set of 40 laser range finder images and 40 structured light scanner images that have manually specified ground truth and (2) a set of defined performance metrics for instances of correctly segmented, missed, and noise regions, over- and under-segmentation, and accuracy of the recovered geometry. A tool is used to objectively compare a machine generated segmentation against the specified ground truth. Four research groups have contributed to evaluate their own algorithm for segmenting a range image into planar patches.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\5ED7CDWB\\Hoover et al. - 1996 - An experimental comparison of range image segmenta.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\TAJ3PHGA\\506791.html},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  keywords = {Artificial intelligence,Computer vision,extraction,Geometrical optics,Geometry,image classification,image segmentation,Image segmentation,Laser noise,laser range finder images,laser ranging,Measurement standards,over-segmentation,performance metrics,Pixel,planar patches,plane,range,range image segmentation algorithms,recovered geometry,Shape,structured light scanner images,Testing,under-segmentation},
  number = {7}
}

@inproceedings{huang_cpp-taskflow_2019,
  title = {Cpp-{{Taskflow}}: {{Fast Task}}-{{Based Parallel Programming Using Modern C}}++},
  shorttitle = {Cpp-{{Taskflow}}},
  booktitle = {2019 {{IEEE International Parallel}} and {{Distributed Processing Symposium}} ({{IPDPS}})},
  author = {Huang, T. and Lin, C. and Guo, G. and Wong, M.},
  year = {2019},
  month = may,
  pages = {974--983},
  issn = {1530-2075},
  doi = {10.1109/IPDPS.2019.00105},
  abstract = {In this paper we introduce Cpp-Taskflow, a new C++ tasking library to help developers quickly write parallel programs using task dependency graphs. Cpp-Taskflow leverages the power of modern C++ and task-based approaches to enable efficient implementations of parallel decomposition strategies. Our programming model can quickly handle not only traditional loop-level parallelism, but also irregular patterns such as graph algorithms, incremental flows, and dynamic data structures. Compared with existing libraries, Cpp-Taskflow is more cost efficient in performance scaling and software integration. We have evaluated Cpp-Taskflow on both micro-benchmarks and real-world applications with million-scale tasking. In a machine learning example, Cpp-Taskflow achieved 1.5-2.7\texttimes{} less coding complexity and 14-38\% speed-up over two industrial-strength libraries OpenMP Tasking and Intel Threading Building Blocks (TBB).},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\STGXLQKX\\Huang et al. - 2019 - Cpp-Taskflow Fast Task-Based Parallel Programming.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\8IKGWEVC\\8821011.html},
  keywords = {C++ language,C++ languages,Cpp-Taskflow,data structures,Heuristic algorithms,industrial-strength libraries OpenMP tasking,Intel Threading Building Block,learning (artificial intelligence),Libraries,machine learning,million-scale tasking,multithreading,parallel decomposition strategies,parallel programming,parallel programming library and model,parallel programs,program compilers,Programming,Task analysis,task dependency graphs,task parallelism,task-based approaches,task-based parallel programming,TBB,Timing,traditional loop-level parallelism,Very large scale integration}
}

@book{iglewicz_how_1993,
  title = {How to {{Detect}} and {{Handle Outliers}}},
  author = {Iglewicz, Boris and Hoaglin, David Caster},
  year = {1993},
  publisher = {{ASQC Quality Press}},
  googlebooks = {siInAQAAIAAJ},
  isbn = {978-0-87389-247-6},
  keywords = {Technology \& Engineering / Reference},
  language = {en}
}

@misc{jeremy_castagno_polylidar3d_2020,
  title = {{{Polylidar3D Kitti Videos}}},
  author = {{Jeremy Castagno}},
  year = {2020},
  note = {Accessed: 2020-06-30}
}

@misc{jeremy_castagno_polylidar3d_2020-1,
  title = {{{Polylidar3D RealSense Videos}}},
  author = {{Jeremy Castagno}},
  year = {2020},
  note = {Accessed: 2020-06-30}
}

@article{jochem_automatic_2009,
  title = {Automatic {{Roof Plane Detection}} and {{Analysis}} in {{Airborne Lidar Point Clouds}} for {{Solar Potential Assessment}}},
  author = {Jochem, Andreas and H{\"o}fle, Bernhard and Rutzinger, Martin and Pfeifer, Norbert},
  year = {2009},
  month = jul,
  volume = {9},
  pages = {5241--5262},
  publisher = {{Molecular Diversity Preservation International}},
  doi = {10.3390/s90705241},
  abstract = {A relative height threshold is defined to separate potential roof points from the point cloud, followed by a segmentation of these points into homogeneous areas fulfilling the defined constraints of roof planes. The normal vector of each laser point is an excellent feature to decompose the point cloud into segments describing planar patches. An objectbased error assessment is performed to determine the accuracy of the presented classification. It results in 94.4\% completeness and 88.4\% correctness. Once all roof planes are detected in the 3D point cloud, solar potential analysis is performed for each point. Shadowing effects of nearby objects are taken into account by calculating the horizon of each point within the point cloud. Effects of cloud cover are also considered by using data from a nearby meteorological station. As a result the annual sum of the direct and diffuse radiation for each roof plane is derived. The presented method uses the full 3D information for both feature extraction and solar potential analysis, which offers a number of new applications in fields where natural processes are influenced by the incoming solar radiation (e.g., evapotranspiration, distribution of permafrost). The presented method detected fully automatically a subset of 809 out of 1,071 roof planes where the arithmetic mean of the annual incoming solar radiation is more than 700 kWh/m2.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\MBUZYB6W\\Jochem et al. - 2009 - Automatic Roof Plane Detection and Analysis in Air.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\PRZJR4FC\\5241.html},
  journal = {Sensors},
  keywords = {3D point cloud,airborne LiDAR,classification,clear sky index,roof plane detection,segmentation,solar radiation},
  language = {en},
  number = {7}
}

@article{kaiser_survey_2019,
  title = {A {{Survey}} of {{Simple Geometric Primitives Detection Methods}} for {{Captured 3D Data}}},
  author = {Kaiser, Adrien and Ybanez Zepeda, Jose Alonso and Boubekeur, Tamy},
  year = {2019},
  month = feb,
  volume = {38},
  pages = {167--196},
  issn = {0167-7055, 1467-8659},
  doi = {10.1111/cgf.13451},
  abstract = {The amount of captured 3D data is continuously increasing, with the democratization of consumer depth cameras, the development of modern multi-view stereo capture setups and the rise of single-view 3D capture based on machine learning. The analysis and representation of this ever growing volume of 3D data, often corrupted with acquisition noise and reconstruction artifacts, is a serious challenge at the frontier between computer graphics and computer vision. To that end, segmentation and optimization are crucial analysis components of the shape abstraction process, which can themselves be greatly simplified when performed on lightened geometric formats. In this survey, we review the algorithms which extract simple geometric primitives from raw dense 3D data. After giving an introduction to these techniques, from the acquisition modality to the underlying theoretical concepts, we propose an application-oriented characterization, designed to help select an appropriate method based on one's application needs, and compare recent approaches. We conclude by giving hints for how to evaluate these methods and a set of research challenges to be explored.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\5ZR2PW9M\\Kaiser et al. - 2019 - A Survey of Simple Geometric Primitives Detection .pdf},
  journal = {Computer Graphics Forum},
  language = {en},
  number = {1}
}

@article{kazhdan_screened_2013,
  title = {Screened Poisson Surface Reconstruction},
  author = {Kazhdan, Michael and Hoppe, Hugues},
  year = {2013},
  month = jul,
  volume = {32},
  pages = {29:1--29:13},
  issn = {0730-0301},
  doi = {10.1145/2487228.2487237},
  abstract = {Poisson surface reconstruction creates watertight surfaces from oriented point sets. In this work we extend the technique to explicitly incorporate the points as interpolation constraints. The extension can be interpreted as a generalization of the underlying mathematical framework to a screened Poisson equation. In contrast to other image and geometry processing techniques, the screening term is defined over a sparse set of points rather than over the full domain. We show that these sparse constraints can nonetheless be integrated efficiently. Because the modified linear system retains the same finite-element discretization, the sparsity structure is unchanged, and the system can still be solved using a multigrid approach. Moreover we present several algorithmic improvements that together reduce the time complexity of the solver to linear in the number of points, thereby enabling faster, higher-quality surface reconstructions.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\PSYWNASH\\Kazhdan and Hoppe - 2013 - Screened poisson surface reconstruction.pdf},
  journal = {ACM Transactions on Graphics},
  keywords = {adaptive octree,finite elements,mesh,Screened Poisson equation,surface fitting},
  number = {3}
}

@article{khuong_array_2017,
  title = {Array {{Layouts}} for {{Comparison}}-{{Based Searching}}},
  author = {Khuong, Paul-Virak and Morin, Pat},
  year = {2017},
  month = may,
  volume = {22},
  pages = {1.3:1--1.3:39},
  issn = {1084-6654},
  doi = {10.1145/3053370},
  abstract = {We attempt to determine the best order and search algorithm to store n comparable data items in an array, A, of length n so we can, for any query value, x, quickly find the smallest value in A that is greater than or equal to x. In particular, we consider the important case where there are many such queries to the same array, A, which resides entirely in RAM. In addition to the obvious sorted order/binary search combination we consider the Eytzinger breadth-first-search (BFS) layout normally used for heaps, an implicit B-tree layout that generalizes the Eytzinger layout, and the van Emde Boas layout commonly used in the cache-oblivious algorithms literature. After extensive testing and tuning on a wide variety of modern hardware, we arrive at the conclusion that, for small values of n, sorted order, combined with a good implementation of binary search, is best. For larger values of n, we arrive at the surprising conclusion that the Eytzinger layout is usually the fastest. The latter conclusion is unexpected and goes counter to earlier experimental work by Brodal, Fagerberg, and Jacob (SODA 2003), who concluded that both the B-tree and van Emde Boas layouts were faster than the Eytzinger layout for large values of n. Our fastest C++ implementations, when compiled, use conditional moves to avoid branch mispredictions and prefetching to reduce cache latency.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\ARB25WPM\\Khuong and Morin - 2017 - Array Layouts for Comparison-Based Searching.pdf},
  journal = {Journal of Experimental Algorithmics},
  keywords = {Binary search,caching,data layouts,microprocessor architecture,pipelining,search}
}

@article{kingma_adam_2017,
  title = {Adam: {{A Method}} for {{Stochastic Optimization}}},
  shorttitle = {Adam},
  author = {Kingma, Diederik P. and Ba, Jimmy},
  year = {2017},
  month = jan,
  abstract = {We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.},
  archivePrefix = {arXiv},
  eprint = {1412.6980},
  eprinttype = {arxiv},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\LQNPX3UV\\Kingma and Ba - 2017 - Adam A Method for Stochastic Optimization.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\9637YAXE\\1412.html},
  journal = {arXiv:1412.6980 [cs]},
  keywords = {Computer Science - Machine Learning},
  note = {Comment: Published as a conference paper at the 3rd International Conference for Learning Representations, San Diego, 2015},
  primaryClass = {cs}
}

@misc{land_nrw_open_2020,
  title = {Open {{Geo Data}}},
  author = {{Land NRW}},
  year = {2020},
  note = {Data licence: Germany - Zero - Version 2.0: https://www.govdata.de/dl-de/zero-2-0
\par
Satellite Images}
}

@incollection{lee_fast_2013,
  title = {Fast {{Range Image Segmentation}} and {{Smoothing Using Approximate Surface Reconstruction}} and {{Region Growing}}},
  booktitle = {Intelligent {{Autonomous Systems}} 12},
  author = {Holz, Dirk and Behnke, Sven},
  editor = {Lee, Sukhan and Cho, Hyungsuck and Yoon, Kwang-Joon and Lee, Jangmyung},
  year = {2013},
  volume = {194},
  pages = {61--73},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-33932-5_7},
  abstract = {Decomposing sensory measurements into relevant parts is a fundamental prerequisite for solving complex tasks, e.g., in the field of mobile manipulation in domestic environments. In this paper, we present a fast approach to surface reconstruction in range images by means of approximate polygonal meshing. The obtained local surface information and neighborhoods are then used to 1) smooth the underlying measurements, and 2) segment the image into planar regions and other geometric primitives. An evaluation using publicly available data sets shows that our approach does not rank behind state-of-the-art algorithms while allowing to process range images at high frame rates.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\FBTVFLW8\\Holz and Behnke - 2013 - Fast Range Image Segmentation and Smoothing Using .pdf},
  isbn = {978-3-642-33931-8 978-3-642-33932-5},
  language = {en}
}

@inproceedings{lee_indoor_2012-1,
  title = {Indoor Mapping Using Planes Extracted from Noisy {{RGB}}-{{D}} Sensors},
  booktitle = {2012 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}}},
  author = {Lee, T. and Lim, S. and Lee, S. and An, S. and Oh, S.},
  year = {2012},
  month = oct,
  pages = {1727--1733},
  issn = {2153-0866},
  doi = {10.1109/IROS.2012.6385909},
  abstract = {This paper presents a fast and robust plane feature extraction and matching technique for RGB-D type sensors. We propose three algorithm components required to utilize the plane features in an online Simultaneous Localization and Mapping (SLAM) problem: fast plane extraction, frame-to-frame constraint estimation, and plane merging. For the fast plane extraction, we estimate local surface normals and curvatures by a simple spherical model and then segment points using a modified flood fill algorithm. In plane parameter estimation, we suggest a new uncertainty estimation method which is robust against the measurement bias, and also introduce a fast boundary modeling method. We associate the plane features based on both the parameters and the spatial coverage, and estimate the stable constraints by the cost function with a regulation term. Also, our plane merging technique provides a way of generating local maps that are useful for estimating loop closure constraints. We have performed real-world experiments at our lab environment. The results demonstrate the efficiency and robustness of the proposed algorithm.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\ZKE2XMMN\\Lee et al. - 2012 - Indoor mapping using planes extracted from noisy R.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\4W38WEYM\\6385909.html},
  keywords = {Cameras,Estimation,feature extraction,Feature extraction,frame-to-frame constraint estimation,Image segmentation,indoor mapping,noisy RGB-D sensors,parameter estimation,plane merging,plane parameter estimation,robust control,robust plane feature extraction,robust plane feature matching,robustness,sensors,Simultaneous localization and mapping,simultaneous localization and mapping problem,SLAM (robots),SLAM problem,stable constraints,uncertainty estimation method,Vectors}
}

@article{lerma_terrestrial_2010,
  title = {Terrestrial Laser Scanning and Close Range Photogrammetry for {{3D}} Archaeological Documentation: The {{Upper Palaeolithic Cave}} of {{Parpall\'o}} as a Case Study},
  shorttitle = {Terrestrial Laser Scanning and Close Range Photogrammetry for {{3D}} Archaeological Documentation},
  author = {Lerma, Jos{\'e} Luis and Navarro, Santiago and Cabrelles, Miriam and Villaverde, Valent{\'i}n},
  year = {2010},
  month = mar,
  volume = {37},
  pages = {499--507},
  issn = {0305-4403},
  doi = {10.1016/j.jas.2009.10.011},
  abstract = {Graphic and metric archaeological documentation is an activity that requires the capture of information from different sources, accurate processing and comprehensive analysis. If monitoring of the state of conservation is required, this task has to be performed before intervention, during and after the completion of the works in a repetitive way. This paper presents the use of terrestrial laser scanning (TLS) in order to effectively produce, prior to intervention, accurate and high-resolution 3D models of a cave with engravings dating back to the Upper Palaeolithic era. The processing of the TLS data is discussed in detail in order to create digital surface models. The complexity of the cave required the integration of two techniques, TLS and close range photogrammetry to yield not only traditional drawings such as sections and elevations, but also photo-realistic perspective views and visual navigation worlds fully operational in 3D environments. This paper demonstrates the potential of integrating TLS and close range photogrammetry to provide both accurate digital surface models and photo-realistic outputs. This processed data can be used to systematically improve archaeological understanding of complex caves and relief panels of prehistoric art with tiny engravings.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\RGEVUWKJ\\Lerma et al. - 2010 - Terrestrial laser scanning and close range photogr.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\UACYLDHN\\S0305440309003781.html},
  journal = {Journal of Archaeological Science},
  keywords = {Analysis,Cave,Close range photogrammetry,Documentation,Interpretation,Rock art,Terrestrial laser scanning},
  language = {en},
  number = {3}
}

@inproceedings{lim_uninformed_2014,
  title = {Uninformed Multigoal Pathfinding on Grid Maps},
  booktitle = {2014 {{International Conference}} on {{Information Science}}, {{Electronics}} and {{Electrical Engineering}}},
  author = {Lim, K. L. and Yeong, L. S. and Ch'ng, S. I. and Seng, K. P. and Ang, L.},
  year = {2014},
  month = apr,
  volume = {3},
  pages = {1552--1556},
  doi = {10.1109/InfoSEEE.2014.6946181},
  abstract = {This paper proposes multigoal implementations of the Dijkstra's shortest path algorithm and the boundary iterative-deepening depth-first search (BIDDFS). The algorithms were modified to allow for the search of more than one goal in a single expansion pass. The aim of this is to reduce the operational redundancy and hence the time taken for calculating multiple start-goal node pairs. Simulations using multigoal algorithms on 250\texttimes{} 250 open grid maps with nine goals have shown up to a 458\% increase in time efficiency.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\69MHJVDT\\Lim et al. - 2014 - Uninformed multigoal pathfinding on grid maps.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\AKL4LEJR\\6946181.html},
  keywords = {Arrays,boundary iterative-deepening depth-first search,Buffer storage,Dijkstra shortest path algorithm,Educational institutions,Electronic mail,graph theory,multigoal algorithms,multiple start-goal node pairs,open grid maps,operational redundancy,Redundancy,Routing,Simulation,tree searching,uninformed multigoal pathfinding}
}

@article{limberger_real-time_2015,
  title = {Real-Time Detection of Planar Regions in Unorganized Point Clouds},
  author = {Limberger, Frederico A. and Oliveira, Manuel M.},
  year = {2015},
  month = jun,
  volume = {48},
  pages = {2043--2053},
  issn = {00313203},
  doi = {10.1016/j.patcog.2014.12.020},
  abstract = {Automatic detection of planar regions in point clouds is an important step for many graphics, image processing, and computer vision applications. While laser scanners and digital photography have allowed us to capture increasingly larger datasets, previous techniques are computationally expensive, being unable to achieve real-time performance for datasets containing tens of thousands of points, even when detection is performed in a non-deterministic way. We present a deterministic technique for plane detection in unorganized point clouds whose cost is O(n log n) in the number of input samples. It is based on an efficient Hough-transform voting scheme and works by clustering approximately co-planar points and by casting votes for these clusters on a spherical accumulator using a trivariate Gaussian kernel. A comparison with competing techniques shows that our approach is considerably faster and scales significantly better than previous ones, being the first practical solution for deterministic plane detection in large unorganized point clouds.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\THQMI7ZN\\Limberger and Oliveira - 2015 - Real-time detection of planar regions in unorganiz.pdf},
  journal = {Pattern Recognition},
  language = {en},
  number = {6}
}

@article{lindsay_whitebox_2016,
  title = {Whitebox {{GAT}}: {{A}} Case Study in Geomorphometric Analysis},
  shorttitle = {Whitebox {{GAT}}},
  author = {Lindsay, J. B.},
  year = {2016},
  month = oct,
  volume = {95},
  pages = {75--84},
  issn = {0098-3004},
  doi = {10.1016/j.cageo.2016.07.003},
  abstract = {This paper describes an open-source geographical information system (GIS) called Whitebox Geospatial Analysis Tools (Whitebox GAT). Whitebox GAT was designed to provide a platform for the rapid development and testing of experimental geospatial analysis methods, supported by its extensible design, integrated facilities for custom plug-in tool authoring, and its novel open-access design philosophy. One of the unique characteristics of Whitebox GAT is the ease with which users can inspect and modify the algorithms for individual geoprocessing tools. The open-access software model that Whitebox GAT adopts is designed to lessen the barriers that are often imposed on end-users when attempting to gain deeper understanding of how a specific function operates. While Whitebox GAT has an extensive range of GIS and remote sensing analytical capabilities, making it broadly suited for advanced scientific research applications in the Earth Sciences, this paper focusses on the software's application in the field of geomorphometry. An airborne LiDAR data set for a small headwater catchment of the Missisquoi River in northern Vermont, USA, was filtered to identify ground-points and then interpolated into a 2.0m resolution bare-Earth DEM. The DEM was processed to remove spurious off-ground objects (mainly buildings), to reduce surface roughness under heavy forest cover, and to hydrologically pre-condition the DEM. These data were then used to extract salient hydrological structures, i.e. the stream network and their associated sub-basins.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\E36VAXZK\\Lindsay - 2016 - Whitebox GAT A case study in geomorphometric anal.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\W29SFZG4\\S0098300416301820.html},
  journal = {Computers \& Geosciences},
  keywords = {Geographic information system,Geomorphometry,Open-source software,Remote sensing software},
  language = {en}
}

@inproceedings{malihi_3d_2016,
  title = {{{3D Building Reconstruction Using Dense Photogrammetric Point Cloud}}},
  booktitle = {{{ISPRS}} - {{International Archives}} of the {{Photogrammetry}}, {{Remote Sensing}} and {{Spatial Information Sciences}}},
  author = {Malihi, S. and Valadan Zoej, M. J. and Hahn, M. and Mokhtarzade, M. and Arefi, H.},
  year = {2016},
  month = jun,
  volume = {XLI-B3},
  pages = {71--74},
  publisher = {{Copernicus GmbH}},
  issn = {1682-1750},
  doi = {10.5194/isprs-archives-XLI-B3-71-2016},
  abstract = {{$<$}p{$><$}strong{$>$}Abstract.{$<$}/strong{$>$} Three dimensional models of urban areas play an important role in city planning, disaster management, city navigation and other applications. Reconstruction of 3D building models is still a challenging issue in 3D city modelling. Point clouds generated from multi view images of UAV is a novel source of spatial data, which is used in this research for building reconstruction. The process starts with the segmentation of point clouds of roofs and walls into planar groups. By generating related surfaces and using geometrical constraints plus considering symmetry, a 3d model of building is reconstructed. In a refinement step, dormers are extracted, and their models are reconstructed. The details of the 3d reconstructed model are in LoD3 level, with respect to modelling eaves, fractions of roof and dormers.{$<$}/p{$>$}},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\DQWJMTEH\\Malihi et al. - 2016 - 3D Building Reconstruction Using Dense Photogramme.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\YQI4UBWQ\\2016.html},
  language = {English}
}

@article{maset_photogrammetric_2017,
  title = {Photogrammetric {{3D Building Reconstruction From Thermal Images}}},
  author = {Maset, E. and Fusiello, A. and Crosilla, F. and Toldo, R. and Zorzetto, D.},
  year = {2017},
  volume = {IV-2/W3},
  pages = {25--32},
  doi = {10.5194/isprs-annals-IV-2-W3-25-2017},
  journal = {ISPRS Annals of Photogrammetry, Remote Sensing and Spatial Information Sciences}
}

@inproceedings{mcdonough_rangr_2018,
  title = {{{RANGR}}: {{Risk Aware Navigation}} and {{Gudiance Resilience}}},
  booktitle = {{{AUVSI Xponential}}},
  author = {McDonough, Kevin and Castagno, Jeremy and Player, Jennifer},
  year = {2018},
  month = may,
  address = {{Denver, CO, USA}},
  abstract = {Player}
}

@incollection{mejias_alvarez_forced_2009,
  title = {Forced Landing Technologies for Unmanned Aerial Vehicles: Towards Safer Operations},
  shorttitle = {Forced Landing Technologies for Unmanned Aerial Vehicles},
  booktitle = {Aerial {{Vehicles}}},
  author = {Mejias Alvarez, Luis and Fitzgerald, Daniel and Eng, Pillar and Liu, Xi},
  editor = {Lam, Than Mung},
  year = {2009},
  pages = {415--442},
  publisher = {{InTech}},
  address = {{Austria}},
  abstract = {While using unmanned systems in combat is not new, what will be new in the foreseeable future is how such systems are used and integrated in the civilian space. The potential use of Unmanned Aerial Vehicles in civil and commercial applications is becoming a fact, and is receiving considerable attention by industry and the research community. The majority of Unmanned Aerial Vehicles performing civilian tasks are restricted to flying only in segregated space, and not within the National Airspace. The areas that UAVs are restricted to flying in are typically not above populated areas, which in turn are the areas most useful for civilian applications. The reasoning behind the current restrictions is mainly due to the fact that current UAV technologies are not able to demonstrate an Equivalent Level of Safety to manned aircraft, particularly in the case of an engine failure which would require an emergency or forced landing. This chapter will preset and guide the reader through a number of developments that would facilitate the integration of UAVs into the National Airspace. Algorithms for UAV Sense-and-Avoid and Force Landings are recognized as two major enabling technologies that will allow the integration of UAVs in the civilian airspace. The following sections will describe some of the techniques that are currently being tested at the Australian Research Centre for Aerospace Automation (ARCAA), which places emphasis on the detection of candidate landing sites using computer vision, the planning of the descent path trajectory for the UAV, and the decision making process behind the selection of the final landing site.},
  copyright = {Copyright 2009 The Authors},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\PS8XDDAV\\Mejias Alvarez et al. - 2009 - Forced landing technologies for unmanned aerial ve.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\KGNDZTA7\\42556.html},
  isbn = {978-953-7619-41-1},
  language = {en}
}

@article{melnyk_third-party_2014-1,
  title = {A Third-Party Casualty Risk Model for Unmanned Aircraft System Operations},
  author = {Melnyk, Richard and Schrage, Daniel and Volovoi, Vitali and Jimenez, Hernando},
  year = {2014},
  month = apr,
  volume = {124},
  pages = {105--116},
  issn = {0951-8320},
  doi = {10.1016/j.ress.2013.11.016},
  abstract = {Unmanned Aircraft System (UAS) integration into the National Airspace System (NAS) is an important goal of many members of the Aerospace community including stakeholders such as the military, law enforcement and potential civil users of UAS. However, integration efforts have remained relatively limited due to safety concerns. Due to the nature of UAS, safety predictions must look beyond the system itself and take the operating environment into account. A framework that can link UAS reliability and physical characteristics to the effects on the bystander population is required. This study proposes using a Target Level of Safety approach and an event tree format, populated with data from existing studies that share characteristics of UAS crashes to enable casualty prediction for UAS operations.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\M3MVJQDN\\Melnyk et al. - 2014 - A third-party casualty risk model for unmanned air.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\WFGG4BDU\\S095183201300313X.html},
  journal = {Reliability Engineering \& System Safety},
  keywords = {Casualties,Reliability,Safety,Target Level of Safety (TLS),Third-party,Unmanned Aircraft Systems (UAS)},
  language = {en}
}

@article{meuleau_emergency_2009,
  title = {An {{Emergency Landing Planner}} for {{Damaged Aircraft}}},
  author = {Meuleau, N. and Plaunt, C. and Smith, D. E. and Smith, T.},
  year = {2009},
  pages = {71--80},
  journal = {Proc. of the 21st Innovative Applications of Artificial Intelligence Conf.}
}

@misc{microsoft_bing_2018,
  title = {Bing {{Maps}}},
  author = {{Microsoft}},
  year = {2018},
  note = {Accessed: 2018-09-05}
}

@article{mohajeri_city-scale_2018,
  title = {A City-Scale Roof Shape Classification Using Machine Learning for Solar Energy Applications},
  author = {Mohajeri, Nahid and Assouline, Dan and Guiboud, Berenice and Bill, Andreas and Gudmundsson, Agust and Scartezzini, Jean-Louis},
  year = {2018},
  month = jun,
  volume = {121},
  pages = {81--93},
  issn = {0960-1481},
  doi = {10.1016/j.renene.2017.12.096},
  abstract = {Solar energy deployment through PV installations in urban areas depends strongly on the shape, size, and orientation of available roofs. Here we use a machine learning approach, Support Vector Machine (SVM) classification, to classify 10,085 building roofs in relation to their received solar energy in the city of Geneva in Switzerland. The SVM correctly identifies six types of roof shapes in 66\% of cases, that is, flat \& shed, gable, hip, gambrel \& mansard, cross/corner gable \& hip, and complex roofs. We classify the roofs based on their useful area for PV installations and potential for receiving solar energy. For most roof shapes, the ratio between useful roof area and building footprint area is close to one, suggesting that footprint is a good measure of useful PV roof area. The main exception is the gable where this ratio is 1.18. The flat and shed roofs have the second highest useful roof area for PV (complex roof being the highest) and the highest PV potential (in GWh). By contrast, hip roof has the lowest PV potential. Solar roof-shape classification provides basic information for designing new buildings, retrofitting interventions on the building roofs, and efficient solar integration on the roofs of buildings.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\S78NMGNG\\Mohajeri et al. - 2018 - A city-scale roof shape classification using machi.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\ECSE58IZ\\S0960148117313009.html},
  journal = {Renewable Energy},
  keywords = {Machine learning,PV potential,Roof shape classification,Support Vector Machine},
  language = {en}
}

@incollection{mokbel_space-filling_2008,
  title = {Space-{{Filling Curves}}},
  booktitle = {Encyclopedia of {{GIS}}},
  author = {Mokbel, Mohamed F. and Aref, Walid G.},
  editor = {Shekhar, Shashi and Xiong, Hui},
  year = {2008},
  pages = {1068--1072},
  publisher = {{Springer US}},
  address = {{Boston, MA}},
  doi = {10.1007/978-0-387-35973-1_1233},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\LGVLGKQM\\Mokbel and Aref - 2008 - Space-Filling Curves.pdf},
  isbn = {978-0-387-35973-1},
  keywords = {Consecutive Point,Geographic Information System,Hilbert Curve,Multimedia Server,Range Query,SFC},
  language = {en}
}

@article{nagle_dasymetric_2014-1,
  title = {Dasymetric {{Modeling}} and {{Uncertainty}}},
  author = {Nagle, Nicholas N. and Buttenfield, Barbara P. and Leyk, Stefan and Spielman, Seth},
  year = {2014},
  month = jan,
  volume = {104},
  pages = {80--95},
  publisher = {{Routledge}},
  issn = {0004-5608},
  doi = {10.1080/00045608.2013.843439},
  abstract = {Dasymetric models increase the spatial resolution of population data by incorporating related ancillary data layers. The role of uncertainty in dasymetric modeling has not been fully addressed as of yet. Uncertainty is usually present because most population data are themselves uncertain, or the geographic processes that connect population and the ancillary data layers are not precisely known. A new dasymetric methodology\textemdash the penalized maximum entropy dasymetric model (P\textendash MEDM)\textemdash is presented that enables these sources of uncertainty to be represented and modeled. The P\textendash MEDM propagates uncertainty through the model and yields fine-resolution population estimates with associated measures of uncertainty. This methodology contains a number of other benefits of theoretical and practical interest. In dasymetric modeling, researchers often struggle with identifying a relationship between population and ancillary data layers. The P\textendash MEDM model simplifies this step by unifying how ancillary data are included. The P\textendash MEDM also allows a rich array of data to be included, with disparate spatial resolutions, attribute resolutions, and uncertainties. Although the P\textendash MEDM does not necessarily produce more precise estimates than do existing approaches, it does help to unify how data enter the dasymetric model, it increases the types of data that can be used, and it allows geographers to characterize the quality of their dasymetric estimates. We present an application of the P\textendash MEDM that includes household-level survey data combined with higher spatial resolution data such as from census tracts, block groups, and land cover classifications.},
  annotation = {\_eprint: https://doi.org/10.1080/00045608.2013.843439},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\9YV8838R\\Nagle et al. - 2014 - Dasymetric Modeling and Uncertainty.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\YL7YPCHE\\00045608.2013.html},
  journal = {Annals of the Association of American Geographers},
  keywords = {dasymetric modeling,entropía máxima,estimación de área pequeña,maximum entropy,modelación dasimétrica,small area estimation,最大熵,分区密度模型,小区域估算},
  number = {1},
  pmid = {25067846}
}

@inproceedings{nash_lazy_2010,
  title = {Lazy Theta*: Any-Angle Path Planning and Path Length Analysis in {{3D}}},
  shorttitle = {Lazy Theta*},
  booktitle = {Proceedings of the {{Twenty}}-{{Fourth AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Nash, Alex and Koenig, Sven and Tovey, Craig},
  year = {2010},
  month = jul,
  pages = {147--154},
  publisher = {{AAAI Press}},
  address = {{Atlanta, Georgia}},
  abstract = {Grids with blocked and unblocked cells are often used to represent continuous 2D and 3D environments in robotics and video games. The shortest paths formed by the edges of 8-neighbor 2D grids can be up to {$\approx$} 8\% longer than the shortest paths in the continuous environment. Theta* typically finds much shorter paths than that by propagating information along graph edges (to achieve short runtimes) without constraining paths to be formed by graph edges (to find short "any-angle" paths). We show in this paper that the shortest paths formed by the edges of 26-neighbor 3D grids can be {$\approx$} 13\% longer than the shortest paths in the continuous environment, which highlights the need for smart path planning algorithms in 3D. Theta* can be applied to 3D grids in a straight-forward manner, but it performs a line-of-sight check for each unexpanded visible neighbor of each expanded vertex and thus it performs many more line-of-sight checks per expanded vertex on a 26-neighbor 3D grid than on an 8-neighbor 2D grid. We therefore introduce Lazy Theta*, a variant of Theta* which uses lazy evaluation to perform only one line-of-sight check per expanded vertex (but with slightly more expanded vertices). We show experimentally that Lazy Theta* finds paths faster than Theta* on 26-neighbor 3D grids, with one order of magnitude fewer line-of-sight checks and without an increase in path length.},
  series = {{{AAAI}}'10}
}

@misc{new_york_state_2016_2018,
  title = {2016 {{Annual Lot New York County}}},
  author = {{New York State}},
  year = {2018},
  note = {Data was retrieved through ArcGIS World Imagery}
}

@inproceedings{ngatchou_pareto_2005,
  title = {Pareto {{Multi Objective Optimization}}},
  booktitle = {Proceedings of the 13th {{International Conference}} on, {{Intelligent Systems Application}} to {{Power Systems}}},
  author = {Ngatchou, P. and Zarei, A. and {El-Sharkawi}, A.},
  year = {2005},
  month = nov,
  pages = {84--91},
  doi = {10.1109/ISAP.2005.1599245},
  abstract = {The goal of this chapter is to give fundamental knowledge on solving multi-objective optimization problems. The focus is on the intelligent metaheuristic approaches (evolutionary algorithms or swarm-based techniques). The focus is on techniques for efficient generation of the Pareto frontier. A general formulation of MO optimization is given in this chapter, the Pareto optimality concepts introduced, and solution approaches with examples of MO problems in the power systems field are given},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\XE8Q5MB2\\Ngatchou et al. - 2005 - Pareto Multi Objective Optimization.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\RBA4IY3F\\1599245.html},
  keywords = {Constraint optimization,Cost function,Delta modulation,evolutionary algorithm,evolutionary computation,Evolutionary computation,intelligent metaheuristic approach,Pareto analysis,pareto multiobjective optimization,Pareto optimazation,Pareto optimisation,Pareto optimization,particle swarm optimisation,particle swarm optimization,Power engineering and energy,power systems,Stability,swarm-based technique,Systems engineering and theory,Voltage}
}

@misc{noauthor_github_2018,
  title = {Github - {{Delaunator}}},
  year = {2018},
  note = {Accessed: 2018-01-05}
}

@misc{noauthor_github_2018-1,
  title = {Github - {{Port}} of {{Delaunator}} to {{C}}++},
  year = {2018},
  note = {Accessed: 2018-01-05}
}

@misc{noauthor_github_2018-3,
  title = {Github - {{Polylabel}}},
  year = {2018},
  note = {Accessed: 2018-01-05}
}

@misc{noauthor_github_2019-1,
  title = {Github - {{Intel RealSense Post Processing}}},
  year = {2019},
  note = {Accessed: 2019-01-05}
}

@misc{noauthor_github_2020-4,
  title = {Github - {{Intel RealSense SDK}}},
  year = {2020},
  note = {Accessed: 2020-06-05}
}

@misc{noauthor_github_2020-7,
  title = {Github - {{A Hybrid Thread}}/{{Fiber Task Scheduler}}},
  year = {2020},
  note = {Accessed: 2020-06-05}
}

@misc{noauthor_github_2020-8,
  title = {Github - {{Google Benchmark}}},
  year = {2020},
  note = {Accessed: 2020-06-05}
}

@misc{noauthor_laser_2018,
  title = {Laser ({{LAS}}) {{File}} Format Exchagne Activities},
  year = {2018},
  note = {Accessed: 2018-09-05}
}

@misc{nyc_open_data_building_2018,
  title = {Building {{Footprints}}},
  author = {NYC Open Data},
  year = {2018},
  publisher = {{New York City}}
}

@incollection{ochoa_fail-safe_2017,
  title = {Fail-{{Safe Navigation}} for {{Autonomous Urban Multicopter Flight}}},
  booktitle = {{{AIAA Information Systems}}-{{AIAA Infotech}} @ {{Aerospace}}},
  author = {Ochoa, Cosme A. and Atkins, Ella M.},
  year = {2017},
  month = jan,
  publisher = {{American Institute of Aeronautics and Astronautics}},
  doi = {10.2514/6.2017-0222},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\BRHQIIRF\\Ochoa and Atkins - 2017 - Fail-Safe Navigation for Autonomous Urban Multicop.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\VBR2KL7E\\6.html},
  keywords = {planning},
  series = {{{AIAA SciTech Forum}}}
}

@article{oesau_planar_2016,
  title = {Planar {{Shape Detection}} and {{Regularization}} in {{Tandem}}: {{Planar Shape Detection}} and {{Regularization}} in {{Tandem}}},
  shorttitle = {Planar {{Shape Detection}} and {{Regularization}} in {{Tandem}}},
  author = {Oesau, Sven and Lafarge, Florent and Alliez, Pierre},
  year = {2016},
  month = feb,
  volume = {35},
  pages = {203--215},
  issn = {01677055},
  doi = {10.1111/cgf.12720},
  abstract = {We present a method for planar shape detection and regularization from raw point sets. The geometric modeling and processing of man-made environments from measurement data often relies upon robust detection of planar primitive shapes. In addition, the detection and reinforcement of regularities between planar parts is a means to increase resilience to missing or defect-laden data as well as to reduce the complexity of models and algorithms down the modeling pipeline. The main novelty behind our method is to perform detection and regularization in tandem. We first sample a sparse set of seeds uniformly on the input point set, then perform in parallel shape detection through region growing, interleaved with regularization through detection and reinforcement of regular relationships (coplanar, parallel and orthogonal). In addition to addressing the end goal of regularization, such reinforcement also improves data fitting and provides guidance for clustering small parts into larger planar parts. We evaluate our approach against a wide range of inputs and under four criteria: geometric fidelity, coverage, regularity and running times. Our approach compares well with available implementations such as the efficient RANSAC-based approach proposed by Schnabel and co-authors in 2007.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\X9A8D4YH\\Oesau et al. - 2016 - Planar Shape Detection and Regularization in Tande.pdf},
  journal = {Computer Graphics Forum},
  language = {en},
  number = {1}
}

@misc{open_nrw_open_2020,
  title = {Open {{Geo Data}}},
  author = {{Open NRW}},
  year = {2020},
  note = {Data licence: Germany - Zero - Version 2.0: https://www.govdata.de/dl-de/zero-2-0
\par
Lidar Data}
}

@misc{open_source_geospatial_foundation_postgis_2019,
  title = {{{PostGIS}}},
  author = {{Open Source Geospatial Foundation}},
  year = {2019},
  howpublished = {[Online] Available: \url{https://postgis.net/docs/ST_ConcaveHull.html}},
  note = {Visited on 2019-01-14}
}

@misc{openstreetmap_contributors_planet_2017,
  title = {Planet Dump Retrieved from {{https://planet.osm.org}}},
  author = {{OpenStreetMap contributors}},
  year = {2017},
  annotation = {Published:  https://www.openstreetmap.org}
}

@article{paris_modified_2013,
  title = {Modified Half-Edge Data Structure and Its Applications to {{3D}} Mesh Generation for Complex Tube Networks.},
  author = {Paris, Richard},
  year = {2013},
  month = may,
  doi = {10.18297/etd/1094},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\D5AJUDFX\\Paris - 2013 - Modified half-edge data structure and its applicat.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\8C9LNQPA\\1094.html},
  journal = {Electronic Theses and Dissertations},
  keywords = {half edge,mesh}
}

@article{partovi_roof_2017,
  title = {Roof {{Type Selection Based}} on {{Patch}}-Based {{Classification Using Deep Learning}} for {{High Resolution Satellite Imagery}}},
  author = {Partovi, T. and Fraundorfer, F. and Azimi, S. and Marmanis, D. and Reinartz, P.},
  year = {2017},
  volume = {XLII-1/W1},
  pages = {653--657},
  doi = {10.5194/isprs-archives-XLII-1-W1-653-2017},
  journal = {ISPRS - International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences}
}

@article{pathak_online_2010,
  title = {Online Three-Dimensional {{SLAM}} by Registration of Large Planar Surface Segments and Closed-Form Pose-Graph Relaxation},
  author = {Pathak, Kaustubh and Birk, Andreas and Vaskevicius, Narunas and Pfingsthorn, Max and Schwertfeger, S{\"o}ren and Poppinga, Jann},
  year = {2010},
  volume = {27},
  pages = {52--84},
  issn = {1556-4967},
  doi = {10.1002/rob.20322},
  abstract = {A fast pose-graph relaxation technique is presented for enhancing the consistency of three-dimensional (3D) maps created by registering large planar surface patches. The surface patches are extracted from point clouds sampled from a 3D range sensor. The plane-based registration method offers an alternative to the state-of-the-art algorithms and provides advantages in terms of robustness, speed, and storage. One of its features is that it results in an accurate determination of rotation, although a lack of predominant surfaces in certain directions may result in translational uncertainty in those directions. Hence, a loop-closing and relaxation problem is formulated that gains significant speed by relaxing only the translational errors and utilizes the full-translation covariance determined during pairwise registration. This leads to a fast 3D simultaneous localization and mapping suited for online operations. The approach is tested in two disaster scenarios that were mapped at the NIST 2008 Response Robot Evaluation Exercise in Disaster City, Texas. The two data sets from a collapsed car park and a flooding disaster consist of 26 and 70 3D scans, respectively. The results of these experiments show that our approach can generate 3D maps without motion estimates by odometry and that it outperforms iterative closest point\textendash based mapping with respect to speed and robustness. \textcopyright{} 2009 Wiley Periodicals, Inc.},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/rob.20322},
  copyright = {Copyright \textcopyright{} 2009 Wiley Periodicals, Inc.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\D4C258HC\\Pathak et al. - 2010 - Online three-dimensional SLAM by registration of l.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\BPMAEPT9\\rob.html},
  journal = {Journal of Field Robotics},
  keywords = {planes,SLAM},
  language = {en},
  number = {1}
}

@article{patterson_timely_2014,
  title = {Timely Autonomous Identification of {{UAV}} Safe Landing Zones},
  author = {Patterson, Timothy and McClean, Sally and Morrow, Philip and Parr, Gerard and Luo, Chunbo},
  year = {2014},
  month = sep,
  volume = {32},
  pages = {568--578},
  issn = {0262-8856},
  doi = {10.1016/j.imavis.2014.06.006},
  abstract = {For many applications such as environmental monitoring in the aftermath of a natural disaster and mountain search-and-rescue, swarms of autonomous Unmanned Aerial Vehicles (UAVs) have the potential to provide a highly versatile and often relatively inexpensive sensing platform. Their ability to operate as an `eye-in-the-sky', processing and relaying real-time colour imagery and other sensor readings facilitate the removal of humans from situations which may be considered dull, dangerous or dirty. However, as with manned aircraft they are likely to encounter errors, the most serious of which may require the UAV to land as quickly and safely as possible. Within this paper we therefore present novel work on autonomously identifying Safe Landing Zones (SLZs) which can be utilised upon occurrence of a safety critical event. Safe Landing Zones are detected and subsequently assigned a safety score either solely using multichannel aerial imagery or, whenever practicable by fusing knowledge in the form of Ordnance Survey (OS) map data with such imagery. Given the real-time nature of the problem we subsequently model two SLZ detection options one of which utilises knowledge enabling the UAV to choose an optimal, viable solution. Results are presented based on colour aerial imagery captured during manned flight demonstrating practical potential in the methods discussed.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\R42YKAW3\\Patterson et al. - 2014 - Timely autonomous identification of UAV safe landi.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\Y7S3ZIXR\\S026288561400105X.html},
  journal = {Image and Vision Computing},
  keywords = {Fuzzy logic,Terrain classification,UAV safe landing zone detection,UAV safety},
  language = {en},
  number = {9}
}

@article{paul_flight_2017,
  title = {Flight {{Trajectory Planning}} for {{Fixed}}-{{Wing Aircraft}} in {{Loss}} of {{Thrust Emergencies}}},
  author = {Paul, Saswata and Hole, Frederick and Zytek, Alexandra and Varela, Carlos A.},
  year = {2017},
  month = oct,
  abstract = {Loss of thrust emergencies-e.g., induced by bird/drone strikes or fuel exhaustion-create the need for dynamic data-driven flight trajectory planning to advise pilots or control UAVs. While total loss of thrust trajectories to nearby airports can be pre-computed for all initial points in a 3D flight plan, dynamic aspects such as partial power and airplane surface damage must be considered for accuracy. In this paper, we propose a new Dynamic Data-Driven Avionics Software (DDDAS) approach which during flight updates a damaged aircraft performance model, used in turn to generate plausible flight trajectories to a safe landing site. Our damaged aircraft model is parameterized on a baseline glide ratio for a clean aircraft configuration assuming best gliding airspeed on straight flight. The model predicts purely geometric criteria for flight trajectory generation, namely, glide ratio and turn radius for different bank angles and drag configurations. Given actual aircraft performance data, we dynamically infer the baseline glide ratio to update the damaged aircraft model. Our new flight trajectory generation algorithm thus can significantly improve upon prior Dubins based trajectory generation work by considering these data-driven geometric criteria. We further introduce a trajectory utility function to rank trajectories for safety. As a use case, we consider the Hudson River ditching of US Airways 1549 in January 2009 using a flight simulator to evaluate our trajectories and to get sensor data. In this case, a baseline glide ratio of 17.25:1 enabled us to generate trajectories up to 28 seconds after the birds strike, whereas, a 19:1 baseline glide ratio enabled us to generate trajectories up to 36 seconds after the birds strike. DDDAS can significantly improve the accuracy of generated flight trajectories thereby enabling better decision support systems for pilots in emergency conditions.},
  archivePrefix = {arXiv},
  eprint = {1711.00716},
  eprinttype = {arxiv},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\WUL227EX\\Paul et al. - 2017 - Flight Trajectory Planning for Fixed-Wing Aircraft.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\CRQ52WEG\\1711.html},
  journal = {arXiv:1711.00716 [cs]},
  keywords = {Electrical Engineering and Systems Science - Systems and Control},
  note = {Comment: This work was accepted as a full paper and presented in the Second International Conference on InfoSymbiotics / DDDAS (Dynamic Data Driven Applications Systems) held at MIT, Cambridge, Massachusetts in August, 2017},
  primaryClass = {cs}
}

@article{pedregosa_scikit-learn_2011,
  title = {Scikit-Learn: {{Machine Learning}} in {{Python}}},
  author = {Pedregosa, F. and Varoquaux, G. and Gramfort, A. and Michel, V. and Thirion, B. and Grisel, O. and Blondel, M. and Prettenhofer, P. and Weiss, R. and Dubourg, V. and Vanderplas, J. and Passos, A. and Cournapeau, D. and Brucher, M. and Perrot, M. and Duchesnay, E.},
  year = {2011},
  volume = {12},
  pages = {2825--2830},
  journal = {Journal of Machine Learning Research}
}

@inproceedings{pham_geometrically_2016-1,
  title = {Geometrically Consistent Plane Extraction for Dense Indoor {{3D}} Maps Segmentation},
  booktitle = {2016 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}} ({{IROS}})},
  author = {Pham, T. T. and Eich, M. and Reid, I. and Wyeth, G.},
  year = {2016},
  month = oct,
  pages = {4199--4204},
  issn = {2153-0866},
  doi = {10.1109/IROS.2016.7759618},
  abstract = {Modern SLAM systems with a depth sensor are able to reliably reconstruct dense 3D geometric maps of indoor scenes. Representing these maps in terms of meaningful entities is a step towards building semantic maps for autonomous robots. One approach is to segment the 3D maps into semantic objects using Conditional Random Fields (CRF), which requires large 3D ground truth datasets to train the classification model. Additionally, the CRF inference is often computationally expensive. In this paper, we present an unsupervised geometric-based approach for the segmentation of 3D point clouds into objects and meaningful scene structures. We approximate an input point cloud by an adjacency graph over surface patches, whose edges are then classified as being either on or off. We devise an effective classifier which utilises both global planar surfaces and local surface convexities for edge classification. More importantly, we propose a novel global plane extraction algorithm for robustly discovering the underlying planes in the scene. Our algorithm is able to enforce the extracted planes to be mutually orthogonal or parallel which conforms usually with human-made indoor environments. We reconstruct 654 3D indoor scenes from NYUv2 sequences to validate the efficiency and effectiveness of our segmentation method.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\VLMLIKNV\\Pham et al. - 2016 - Geometrically consistent plane extraction for dens.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\W2PYE5DQ\\7759618.html},
  keywords = {3D ground truth datasets,adjacency graph,autonomous robots,classification model,Clustering algorithms,conditional random fields,CRF,dense indoor 3D maps segmentation,edge classification,feature extraction,geometrically consistent plane extraction,global plane extraction algorithm,graph theory,image classification,Image reconstruction,image segmentation,Image segmentation,image sequences,NYUv2 sequences,robot vision,Robots,Semantics,simultaneous localization and mapping,SLAM (robots),SLAM systems,Surface reconstruction,Three-dimensional displays,unsupervised geometric-based approach}
}

@inproceedings{pham_scenecut_2018,
  title = {{{SceneCut}}: {{Joint Geometric}} and {{Object Segmentation}} for {{Indoor Scenes}}},
  shorttitle = {{{SceneCut}}},
  booktitle = {2018 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Pham, Trung T. and Do, Thanh-Toan and S{\"u}nderhauf, Niko and Reid, Ian},
  year = {2018},
  month = may,
  pages = {3213--3220},
  issn = {2577-087X},
  doi = {10.1109/ICRA.2018.8461108},
  abstract = {This paper presents SceneCut, a novel approach to jointly discover previously unseen objects and non-object surfaces using a single RGB-D image. SceneCut's joint reasoning over scene semantics and geometry allows a robot to detect and segment object instances in complex scenes where modern deep learning-based methods either fail to separate object instances, or fail to detect objects that were not seen during training. SceneCut automatically decomposes a scene into meaningful regions which either represent objects or scene surfaces. The decomposition is qualified by an unified energy function over objectness and geometric fitting. We show how this energy function can be optimized efficiently by utilizing hierarchical segmentation trees. Moreover, we leverage a pre-trained convolutional oriented boundary network to predict accurate boundaries from images, which are used to construct high-quality region hierarchies. We evaluate SceneCut on several different indoor environments, and the results show that SceneCut significantly outperforms all the existing methods.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\9JLK2D3M\\Pham et al. - 2018 - SceneCut Joint Geometric and Object Segmentation .pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\BGCXSMJD\\8461108.html},
  keywords = {convolutional oriented boundary network,deep learning,deep learning-based methods,geometry,hierarchical segmentation trees,image colour analysis,image representation,image segmentation,Image segmentation,indoor scenes,joint geometric,learning (artificial intelligence),nonobject surfaces,object detection,object segmentation,Object segmentation,RGB-D image,Robots,scene semantics,scene surfaces,SceneCut,Semantics,Silicon,Three-dimensional displays,Training,unified energy function,unseen objects}
}

@inproceedings{poppinga_fast_2008,
  title = {Fast Plane Detection and Polygonalization in Noisy {{3D}} Range Images},
  booktitle = {2008 {{IEEE}}/{{RSJ International Conference}} on {{Intelligent Robots}} and {{Systems}}},
  author = {Poppinga, J. and Vaskevicius, N. and Birk, A. and Pathak, K.},
  year = {2008},
  month = sep,
  pages = {3378--3383},
  publisher = {{IEEE}},
  address = {{Nice}},
  doi = {10.1109/IROS.2008.4650729},
  abstract = {A very fast but nevertheless accurate approach for surface extraction from noisy 3D point clouds is presented. It consists of two parts, namely a plane fitting and a polygonalization step. Both exploit the sequential nature of 3D data acquisition on mobile robots in form of range images. For the plane fitting, this is used to revise the standard mathematical formulation to an incremental version, which allows a linear computation. For the polygonalization, the neighborhood relation in range images is exploited. Experiments are presented using a time-of-flight range camera in form of a Swissranger SR-3000. Results include lab scenes as well as data from two runs of the rescue robot league at the RoboCup German Open 2007 with 1,414, respectively 2,343 sensor snapshots. The 36{$\cdot$}106, respectively 59{$\cdot$}106 points from the two point clouds are reduced to about 14{$\cdot$}103, respectively 23{$\cdot$}103 planes with only about 0.2 sec of total computation time per snapshot while the robot moves along.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\DUVYGNDB\\Poppinga et al. - 2008 - Fast plane detection and polygonalization in noisy.pdf},
  isbn = {978-1-4244-2057-5 978-1-4244-2058-2},
  language = {en}
}

@inproceedings{prevot_uas_2016,
  title = {{{UAS Traffic Management}} ({{UTM}}) {{Concept}} of {{Operations}} to {{Safely Enable Low Altitude Flight Operations}}},
  booktitle = {16th {{AIAA Aviation Technology}}, {{Integration}}, and {{Operations Conference}}},
  author = {Prevot, Thomas and Rios, Joseph and Kopardekar, Parimal and III, John E. Robinson and Johnson, Marcus and Jung, Jaewoo},
  year = {2016},
  month = jun,
  publisher = {{American Institute of Aeronautics and Astronautics}},
  doi = {10.2514/6.2016-3292}
}

@article{primatesta_ground_2020,
  title = {Ground {{Risk Map}} for {{Unmanned Aircraft}} in {{Urban Environments}}},
  author = {Primatesta, Stefano and Rizzo, Alessandro and {la Cour-Harbo}, Anders},
  year = {2020},
  month = mar,
  volume = {97},
  pages = {489--509},
  issn = {1573-0409},
  doi = {10.1007/s10846-019-01015-z},
  abstract = {The large diversity of unmanned aircraft requires a suitable and proper risk assessment. In this paper, we propose the use of risk maps to define the risk associated to accidents with unmanned aircraft. It is a two-dimensional location-based map that quantifies the risk to the population on ground of flight operations over a specified area. The risk map is generated through a probabilistic approach and combines several layers, including population density, sheltering factor, no-fly zones, and obstacles. Each element of the risk map has associated a risk value that quantifies the risk of flying over a specific location. Risk values are defined by a risk assessment process using different uncontrolled descent events, drone parameters, environmental characteristics, as well as uncertainties on parameters. The risk map is able to quantify the risk of large areas, such as urban environments, and allows for easy identification of high and low-risk locations. The map is a tool for informed decision making, and our results report some examples of risk map with different aircraft in a realistic urban environment.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\947P9U9T\\Primatesta et al. - 2020 - Ground Risk Map for Unmanned Aircraft in Urban Env.pdf},
  journal = {Journal of Intelligent \& Robotic Systems},
  language = {en},
  number = {3}
}

@misc{proj_contributors_proj_2018,
  title = {{{PROJ}} Coordinate Transformation Software Library},
  author = {{PROJ contributors}},
  year = {2018},
  publisher = {{Open Source Geospatial Foundation}}
}

@incollection{qi_pointnet_2017-1,
  title = {{{PointNet}}++: {{Deep Hierarchical Feature Learning}} on {{Point Sets}} in a {{Metric Space}}},
  booktitle = {Advances in {{Neural Information Processing Systems}} 30},
  author = {Qi, Charles Ruizhongtai and Yi, Li and Su, Hao and Guibas, Leonidas J},
  editor = {Guyon, I. and Luxburg, U. V. and Bengio, S. and Wallach, H. and Fergus, R. and Vishwanathan, S. and Garnett, R.},
  year = {2017},
  pages = {5099--5108},
  publisher = {{Curran Associates, Inc.}}
}

@article{richard_shewchuk_adaptive_1997,
  title = {Adaptive {{Precision Floating}}-{{Point Arithmetic}} and {{Fast Robust Geometric Predicates}}},
  author = {Richard Shewchuk, Jonathan},
  year = {1997},
  month = oct,
  volume = {18},
  pages = {305--363},
  issn = {1432-0444},
  doi = {10.1007/PL00009321},
  abstract = {. Exact computer arithmetic has a variety of uses, including the robust implementation of geometric algorithms. This article has three purposes. The first is to offer fast software-level algorithms for exact addition and multiplication of arbitrary precision floating-point values. The second is to propose a technique for adaptive precision arithmetic that can often speed these algorithms when they are used to perform multiprecision calculations that do not always require exact arithmetic, but must satisfy some error bound. The third is to use these techniques to develop implementations of several common geometric calculations whose required degree of accuracy depends on their inputs. These robust geometric predicates are adaptive; their running time depends on the degree of uncertainty of the result, and is usually small. These algorithms work on computers whose floating-point arithmetic uses radix two and exact rounding, including machines complying with the IEEE 754 standard. The inputs to the predicates may be arbitrary single or double precision floating-point numbers. C code is publicly available for the two-dimensional and three-dimensional orientation and incircle tests, and robust Delaunay triangulation using these tests. Timings of the implementations demonstrate their effectiveness.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\7TMT75CV\\Richard Shewchuk - 1997 - Adaptive Precision Floating-Point Arithmetic and F.pdf},
  journal = {Discrete \& Computational Geometry},
  keywords = {Computer Arithmetic,Delaunay Triangulation,Double Precision,Exact Computer,Geometric Calculation,geometry robust predicates},
  language = {en},
  number = {3}
}

@article{rottensteiner_results_2014,
  title = {Results of the {{ISPRS}} Benchmark on Urban Object Detection and {{3D}} Building Reconstruction},
  author = {Rottensteiner, Franz and Sohn, Gunho and Gerke, Markus and Wegner, Jan Dirk and Breitkopf, Uwe and Jung, Jaewook},
  year = {2014},
  month = jul,
  volume = {93},
  pages = {256--271},
  issn = {0924-2716},
  doi = {10.1016/j.isprsjprs.2013.10.004},
  abstract = {For more than two decades, many efforts have been made to develop methods for extracting urban objects from data acquired by airborne sensors. In order to make the results of such algorithms more comparable, benchmarking data sets are of paramount importance. Such a data set, consisting of airborne image and laserscanner data, has been made available to the scientific community by ISPRS WGIII/4. Researchers were encouraged to submit their results of urban object detection and 3D building reconstruction, which were evaluated based on reference data. This paper presents the outcomes of the evaluation for building detection, tree detection, and 3D building reconstruction. The results achieved by different methods are compared and analysed to identify promising strategies for automatic urban object extraction from current airborne sensor data, but also common problems of state-of-the-art methods.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\HALUA2T7\\Rottensteiner et al. - 2014 - Results of the ISPRS benchmark on urban object det.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\55KZN6R7\\S0924271613002268.html},
  journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
  keywords = {3D building reconstruction,Aerial imagery,Automatic object extraction,Benchmarking test,Evaluation,Laser scanning},
  language = {en}
}

@inproceedings{rusinkiewicz_efficient_2001,
  title = {Efficient Variants of the {{ICP}} Algorithm},
  booktitle = {Proceedings {{Third International Conference}} on 3-{{D Digital Imaging}} and {{Modeling}}},
  author = {Rusinkiewicz, S. and Levoy, M.},
  year = {2001},
  month = may,
  pages = {145--152},
  doi = {10.1109/IM.2001.924423},
  abstract = {The ICP (Iterative Closest Point) algorithm is widely used for geometric alignment of three-dimensional models when an initial estimate of the relative pose is known. Many variants of ICP have been proposed, affecting all phases of the algorithm from the selection and matching of points to the minimization strategy. We enumerate and classify many of these variants, and evaluate their effect on the speed with which the correct alignment is reached. In order to improve convergence for nearly-flat meshes with small features, such as inscribed surfaces, we introduce a new variant based on uniform sampling of the space of normals. We conclude by proposing a combination of ICP variants optimized for high speed. We demonstrate an implementation that is able to align two range images in a few tens of milliseconds, assuming a good initial guess. This capability has potential application to real-time 3D model acquisition and model-based tracking.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\WBSNT6M6\\Rusinkiewicz and Levoy - 2001 - Efficient variants of the ICP algorithm.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\J5MVU7E2\\924423.html},
  keywords = {Convergence,distance measurement,geometric alignment,Geometry,icp,image processing,Image sampling,inscribed surfaces,Iterative algorithms,iterative closest point algorithm,Iterative closest point algorithm,Iterative methods,Layout,minimisation,Minimization methods,minimization strategy,model-based tracking,nearly-flat meshes,plane,range images,real-time 3D model acquisition,real-time systems,Rough surfaces,Solid modeling,three-dimensional models,uniform sampling}
}

@article{russakovsky_imagenet_2015,
  title = {{{ImageNet Large Scale Visual Recognition Challenge}}},
  author = {Russakovsky, Olga and Deng, Jia and Su, Hao and Krause, Jonathan and Satheesh, Sanjeev and Ma, Sean and Huang, Zhiheng and Karpathy, Andrej and Khosla, Aditya and Bernstein, Michael and Berg, Alexander C. and {Fei-Fei}, Li},
  year = {2015},
  month = dec,
  volume = {115},
  pages = {211--252},
  issn = {1573-1405},
  doi = {10.1007/s11263-015-0816-y},
  abstract = {The ImageNet Large Scale Visual Recognition Challenge is a benchmark in object category classification and detection on hundreds of object categories and millions of images. The challenge has been run annually from 2010 to present, attracting participation from more than fifty institutions. This paper describes the creation of this benchmark dataset and the advances in object recognition that have been possible as a result. We discuss the challenges of collecting large-scale ground truth annotation, highlight key breakthroughs in categorical object recognition, provide a detailed analysis of the current state of the field of large-scale image classification and object detection, and compare the state-of-the-art computer vision accuracy with human accuracy. We conclude with lessons learned in the 5~years of the challenge, and propose future directions and improvements.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\RQTFB8S7\\Russakovsky et al. - 2015 - ImageNet Large Scale Visual Recognition Challenge.pdf},
  journal = {International Journal of Computer Vision},
  language = {en},
  number = {3}
}

@inproceedings{saha_planning_2003,
  title = {Planning Multi-Goal Tours for Robot Arms},
  booktitle = {2003 {{IEEE International Conference}} on {{Robotics}} and {{Automation}} ({{Cat}}. {{No}}.{{03CH37422}})},
  author = {Saha, M. and {Sanchez-Ante}, G. and Latombe, J.-},
  year = {2003},
  month = sep,
  volume = {3},
  pages = {3797-3803 vol.3},
  issn = {1050-4729},
  doi = {10.1109/ROBOT.2003.1242179},
  abstract = {This paper considers the following multi-goal motion planning problem: a robot arm must reach several goal configurations in some sequence, but this sequence is not given. Instead, the robot's planner must compute an optimal or near-optimal path through the goals. This problem occurs, for instance, in spot-welding, inspection, and measurement tasks. It combines two computationally hard sub-problems: the shortest-path and traveling-salesman problems. This paper describes a greedy algorithm that operates under the assumption that the number of goals is relatively small (a few dozen at most) and the computational cost of finding a good path between two goals dominates that of finding a good tour in a graph with edges of given costs. Although the algorithm computes a quadratic number of goal-to-goal paths in the worst case, it is much faster in practice.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\4BKFVS9V\\Saha et al. - 2003 - Planning multi-goal tours for robot arms.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\4EEAYM39\\1242179.html},
  keywords = {algorithm theory,Computational efficiency,Computer science,goal-to-goal paths,greedy algorithm,Greedy algorithms,industrial manipulators,Inspection,Manipulators,Motion planning,multigoal motion planning,optimal path planning,Orbital robotics,path planning,quadratic number,robot arms,Robotic assembly,Robots,shortest path problem,spot welding,traveling salesman problems,travelling salesman problems,Welding}
}

@inproceedings{salas-moreno_dense_2014,
  title = {Dense Planar {{SLAM}}},
  booktitle = {2014 {{IEEE International Symposium}} on {{Mixed}} and {{Augmented Reality}} ({{ISMAR}})},
  author = {{Salas-Moreno}, Renato F. and Glocken, Ben and Kelly, Paul H. J. and Davison, Andrew J.},
  year = {2014},
  month = sep,
  pages = {157--164},
  issn = {null},
  doi = {10.1109/ISMAR.2014.6948422},
  abstract = {Using higher-level entities during mapping has the potential to improve camera localisation performance and give substantial perception capabilities to real-time 3D SLAM systems. We present an efficient new real-time approach which densely maps an environment using bounded planes and surfels extracted from depth images (like those produced by RGB-D sensors or dense multi-view stereo reconstruction). Our method offers the every-pixel descriptive power of the latest dense SLAM approaches, but takes advantage directly of the planarity of many parts of real-world scenes via a data-driven process to directly regularize planar regions and represent their accurate extent efficiently using an occupancy approach with on-line compression. Large areas can be mapped efficiently and with useful semantic planar structure which enables intuitive and useful AR applications such as using any wall or other planar surface in a scene to display a user's content.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\VRVNENN8\\Salas-Moreno et al. - 2014 - Dense planar SLAM.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\GXTAAIDW\\6948422.html},
  keywords = {3D SLAM system,AR applications,Artificial,augmented,augmented reality,bounded planes,Cameras,Computing methodologies [Reconstruction]. Computing methodologies [Image Processing and Computer Vision]: Segmentation. Information Systems [Information Interfaces and Presentation],Computing methodologies [Scene understanding],dense multiview stereo reconstruction,dense planar SLAM,feature extraction,image reconstruction,Indexes,Noise,Real-time systems,red-green-blue-depth sensor,RGB-D sensors,Simultaneous localization and mapping,simultaneous localization and planning,slam,SLAM (robots),stereo image processing,surfel extraction,surfels,Three-dimensional displays,virtual realities}
}

@phdthesis{samosky_sectionviewsystem_1993,
  title = {{{SectionView}}\textendash{{A}} System for Interactively Specifying and Visualizing Sections through Three-Dimensional Medical Image Data},
  author = {Samosky, Joseph Thomas},
  year = {1993},
  school = {Massachusetts Institute of Technology, Department of Electrical Engineering and Computer Science},
  type = {{{PhD Thesis}}}
}

@incollection{sankararaman_towards_2017,
  title = {Towards {{A Computational Framework}} for {{Autonomous Decision}}-{{Making}} in {{Unmanned Aerial Vehicles}}},
  booktitle = {{{AIAA Information Systems}}-{{AIAA Infotech}} @ {{Aerospace}}},
  author = {Sankararaman, Shankar},
  year = {2017},
  month = jan,
  publisher = {{American Institute of Aeronautics and Astronautics}},
  doi = {10.2514/6.2017-0446},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\2UVKWRHT\\Sankararaman - 2017 - Towards A Computational Framework for Autonomous D.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\KX75HFYD\\6.html},
  series = {{{AIAA SciTech Forum}}}
}

@article{sarne_multi-goal_2010,
  title = {Multi-Goal Economic Search Using Dynamic Search Structures},
  author = {Sarne, David and Manisterski, Efrat and Kraus, Sarit},
  year = {2010},
  month = sep,
  volume = {21},
  pages = {204--236},
  issn = {1573-7454},
  doi = {10.1007/s10458-009-9111-z},
  abstract = {This paper investigates cooperative search strategies for agents engaged in costly search in a complex environment. Searching cooperatively, several search goals can be satisfied within a single search effort. Given the searchers' preferences, the goal is to conduct a search in a way that the expected overall utility out of the set of opportunities found (e.g., products when operating in a market) minus the costs associated with finding that set is maximized. This search scheme, given in the context of a group search, applies also to scenarios where a single agent has to search for a set of items for satisfying several different goals. The uniqueness of the proposed mechanism is in the ability to partition the group of agents/goals into sub-groups where the search continues for each group autonomously. As we show throughout the paper, this strategy is favorable as it weakly dominates (i.e., can improve but never worsen) cooperative and autonomous search techniques. The paper presents a comprehensive analysis of the new search method and highlights the specific characteristics of the optimal search strategy. Furthermore, we introduce innovative algorithms for extracting the optimal search strategy in a range of common environments, that eliminates the computational overhead associated with the use of the partitioning technique.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\DIZUGDRA\\Sarne et al. - 2010 - Multi-goal economic search using dynamic search st.pdf},
  journal = {Autonomous Agents and Multi-Agent Systems},
  language = {en},
  number = {2}
}

@inproceedings{schaefer_maximum_2019,
  title = {A {{Maximum Likelihood Approach}} to {{Extract Finite Planes}} from 3-{{D Laser Scans}}},
  booktitle = {2019 {{International Conference}} on {{Robotics}} and {{Automation}} ({{ICRA}})},
  author = {Schaefer, Alexander and Vertens, Johan and Buscher, Daniel and Burgard, Wolfram},
  year = {2019},
  month = may,
  pages = {72--78},
  publisher = {{IEEE}},
  address = {{Montreal, QC, Canada}},
  doi = {10.1109/ICRA.2019.8794318},
  abstract = {Whether it is object detection, model reconstruction, laser odometry, or point cloud registration: Plane extraction is a vital component of many robotic systems. In this paper, we propose a strictly probabilistic method to detect finite planes in organized 3-D laser range scans. An agglomerative hierarchical clustering technique, our algorithm builds planes from bottom up, always extending a plane by the point that decreases the measurement likelihood of the scan the least. In contrast to most related methods, which rely on heuristics like orthogonal point-to-plane distance, we leverage the ray path information to compute the measurement likelihood. We evaluate our approach not only on the popular SegComp benchmark, but also provide a challenging synthetic dataset that overcomes SegComp's deficiencies. Both our implementation and the suggested dataset are available at [1].},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\VES4XRC6\\Schaefer et al. - 2019 - A Maximum Likelihood Approach to Extract Finite Pl.pdf},
  isbn = {978-1-5386-6027-0},
  language = {en}
}

@article{schmidhuber_deep_2015,
  title = {Deep Learning in Neural Networks: {{An}} Overview},
  shorttitle = {Deep Learning in Neural Networks},
  author = {Schmidhuber, J{\"u}rgen},
  year = {2015},
  month = jan,
  volume = {61},
  pages = {85--117},
  issn = {0893-6080},
  doi = {10.1016/j.neunet.2014.09.003},
  abstract = {In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarizes relevant work, much of it from the previous millennium. Shallow and Deep Learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning \& evolutionary computation, and indirect search for short programs encoding deep and large networks.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\CDV3ELWC\\Schmidhuber - 2015 - Deep learning in neural networks An overview.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\IH7GX4QR\\S0893608014002135.html},
  journal = {Neural Networks},
  keywords = {Deep learning,Evolutionary computation,Reinforcement learning,Supervised learning,Unsupervised learning},
  language = {en}
}

@article{stevenson_estimated_2015-1,
  title = {Estimated Levels of Safety for Small Unmanned Aerial Vehicles and Risk Mitigation Strategies},
  author = {Stevenson, Jonathan D. and O'Young, Siu and Rolland, Luc},
  year = {2015},
  month = sep,
  publisher = {{NRC Research Press  http://www.nrcresearchpress.com}},
  doi = {10.1139/juvs-2014-0016},
  abstract = {In this paper the risks posed by small unmanned aerial vehicles (UAV)1 are determined using quantitative methods, to calculate the estimated level of safety (ELS). The aim is to determine if the us...},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\QV6DRX77\\juvs-2014-0016.html},
  journal = {Journal of Unmanned Vehicle Systems},
  language = {en}
}

@article{sun_fast_2007,
  title = {Fast and {{Effective Feature}}-{{Preserving Mesh Denoising}}},
  author = {Sun, Xianfang and Rosin, Paul L. and Martin, Ralph and Langbein, Frank},
  year = {2007},
  month = sep,
  volume = {13},
  pages = {925--938},
  issn = {1077-2626, 1941-0506, 2160-9306},
  doi = {10.1109/TVCG.2007.1065},
  abstract = {We present a simple and fast mesh denoising method, which can remove noise effectively, while preserving mesh features such as sharp edges and corners. The method consists of two stages. Firstly, noisy face normals are filtered iteratively by weighted averaging of neighboring face normals. Secondly, vertex positions are iteratively updated to agree with the denoised face normals. The weight function used during normal filtering is much simpler than that used in previous similar approaches, being simply a trimmed quadratic. This makes the algorithm both fast and simple to implement. Vertex position updating is based on the integration of surface normals using a least-squares error criterion. Like previous algorithms, we solve the least-squares problem by gradient descent, but whereas previous methods needed user input to determine the iteration step size, we determine it automatically. In addition, we prove the convergence of the vertex position updating approach. Analysis and experiments show the advantages of our proposed method over various earlier surface denoising methods.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\VA3TCEUT\\Sun et al. - 2007 - Fast and Effective Feature-Preserving Mesh Denoisi.pdf},
  journal = {IEEE Transactions on Visualization and Computer Graphics},
  language = {en},
  number = {5}
}

@article{suveg_reconstruction_2004,
  title = {Reconstruction of {{3D}} Building Models from Aerial Images and Maps},
  author = {Suveg, Ildiko and Vosselman, George},
  year = {2004},
  month = jan,
  volume = {58},
  pages = {202--224},
  issn = {0924-2716},
  doi = {10.1016/j.isprsjprs.2003.09.006},
  abstract = {Automatic 3D building reconstruction has becoming increasingly important for a number of applications. The reconstruction of buildings using only aerial images as data source has been proven to be a very difficult problem. The complexity of the reconstruction can be greatly reduced by combining the aerial images with other data sources. In this paper, we describe a 3D building reconstruction method that integrates the aerial image analysis with information from large-scale 2D Geographic Information System (GIS) databases and domain knowledge. By combining the images with GIS data, the specific strengths of both the images (high resolution, accuracy, and large-information content) and the GIS data (relatively simple interpretation) are exploited.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\AD4QYXKE\\Suveg and Vosselman - 2004 - Reconstruction of 3D building models from aerial i.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\7UBEPY7Y\\S0924271603000583.html},
  journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
  keywords = {3D reconstruction,aerial images,domain knowledge,evaluation,fitting,GIS database,hypotheses generation},
  language = {en},
  number = {3},
  series = {Integration of {{Geodata}} and {{Imagery}} for {{Automated Refinement}} and {{Update}} of {{Spatial Databases}}}
}

@inproceedings{szegedy_inception-v4_2017,
  title = {Inception-v4, Inception-{{ResNet}} and the Impact of Residual Connections on Learning},
  booktitle = {Proceedings of the {{Thirty}}-{{First AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Szegedy, Christian and Ioffe, Sergey and Vanhoucke, Vincent and Alemi, Alexander A.},
  year = {2017},
  month = feb,
  pages = {4278--4284},
  publisher = {{AAAI Press}},
  address = {{San Francisco, California, USA}},
  abstract = {Very deep convolutional networks have been central to the largest advances in image recognition performance in recent years. One example is the Inception architecture that has been shown to achieve very good performance at relatively low computational cost. Recently, the introduction of residual connections in conjunction with a more traditional architecture has yielded state-of-the-art performance in the 2015 ILSVRC challenge; its performance was similar to the latest generation Inception-v3 network. This raises the question: Are there any benefits to combining Inception architectures with residual connections? Here we give clear empirical evidence that training with residual connections accelerates the training of Inception networks significantly. There is also some evidence of residual Inception networks outperforming similarly expensive Inception networks without residual connections by a thin margin. We also present several new streamlined architectures for both residual and non-residual Inception networks. These variations improve the single-frame recognition performance on the ILSVRC 2012 classification task significantly. We further demonstrate how proper activation scaling stabilizes the training of very wide residual Inception networks. With an ensemble of three residual and one Inception-v4 networks, we achieve 3.08\% top-5 error on the test set of the ImageNet classification (CLS) challenge.},
  series = {{{AAAI}}'17}
}

@inproceedings{szegedy_rethinking_2016,
  title = {Rethinking the {{Inception Architecture}} for {{Computer Vision}}},
  booktitle = {2016 {{IEEE Conference}} on {{Computer Vision}} and {{Pattern Recognition}} ({{CVPR}})},
  author = {Szegedy, C. and Vanhoucke, V. and Ioffe, S. and Shlens, J. and Wojna, Z.},
  year = {2016},
  month = jun,
  pages = {2818--2826},
  issn = {1063-6919},
  doi = {10.1109/CVPR.2016.308},
  abstract = {Convolutional networks are at the core of most state of-the-art computer vision solutions for a wide variety of tasks. Since 2014 very deep convolutional networks started to become mainstream, yielding substantial gains in various benchmarks. Although increased model size and computational cost tend to translate to immediate quality gains for most tasks (as long as enough labeled data is provided for training), computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios. Here we are exploring ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization. We benchmark our methods on the ILSVRC 2012 classification challenge validation set demonstrate substantial gains over the state of the art: 21:2\% top-1 and 5:6\% top-5 error for single frame evaluation using a network with a computational cost of 5 billion multiply-adds per inference and with using less than 25 million parameters. With an ensemble of 4 models and multi-crop evaluation, we report 3:5\% top-5 error and 17:3\% top-1 error on the validation set and 3:6\% top-5 error on the official test set.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\EYRL6HM9\\Szegedy et al. - 2016 - Rethinking the Inception Architecture for Computer.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\HS6UKQLD\\7780677.html},
  keywords = {Benchmark testing,Computational efficiency,Computational modeling,Computer architecture,computer vision,Computer vision,Convolution,deep convolutional networks,ILSVRC 2012 classification challenge validation set,image classification,inception architecture,neural nets,Training}
}

@article{tack_3d_2012,
  title = {{{3D}} Building Reconstruction Based on given Ground Plan Information and Surface Models Extracted from Spaceborne Imagery},
  author = {Tack, Frederik and Buyuksalih, Gurcan and Goossens, Rudi},
  year = {2012},
  month = jan,
  volume = {67},
  pages = {52--64},
  issn = {0924-2716},
  doi = {10.1016/j.isprsjprs.2011.10.003},
  abstract = {3D surface models have gained field as an important tool for urban planning and mapping. However, urban environments have a complex nature to model and they provide a challenge to investigate the current limits of automatic digital surface modeling from high resolution satellite imagery. An approach is introduced to improve a 3D surface model, extracted photogrammetrically from satellite imagery, based on the geometric building information embodied in existing 2D ground plans. First buildings are clipped from the extracted DSM based on the 2D polygonal building ground plans. To generate prismatic shaped structures with vertical walls and flat roofs, building shape is retrieved from the cadastre database while elevation information is extracted from the DSM. Within each 2D building boundary, a constant roof height is extracted based on statistical calculations of the height values. After buildings are extracted from the initial surface model, the remaining DSM is further processed to simplify to a smooth DTM that reflects bare ground, without artifacts, local relief, vegetation, cars and city furniture. In a next phase, both models are merged to yield an integrated city model or generalized DSM. The accuracy of the generalized surface model is assessed according to a quantitative-statistical analysis by comparison with two different types of reference data.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\CUQV8ZBG\\Tack et al. - 2012 - 3D building reconstruction based on given ground p.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\RXQDSRDE\\S0924271611001134.html},
  journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
  keywords = {2D ground plans,3D city modeling,DSM,High resolution satellite imagery,Photogrammetry},
  language = {en}
}

@article{taillandier_automatic_2005,
  title = {Automatic Building Reconstruction from Cadastral Maps and Aerial Images},
  author = {Taillandier, Franck},
  year = {2005},
  volume = {36},
  pages = {W24},
  journal = {International Archives of Photogrammetry and Remote Sensing},
  number = {Part 3}
}

@article{tang_deep_2015,
  title = {Deep {{Learning}} Using {{Linear Support Vector Machines}}},
  author = {Tang, Yichuan},
  year = {2015},
  month = feb,
  abstract = {Recently, fully-connected and convolutional neural networks have been trained to achieve state-of-the-art performance on a wide variety of tasks such as speech recognition, image classification, natural language processing, and bioinformatics. For classification tasks, most of these "deep learning" models employ the softmax activation function for prediction and minimize cross-entropy loss. In this paper, we demonstrate a small but consistent advantage of replacing the softmax layer with a linear support vector machine. Learning minimizes a margin-based loss instead of the cross-entropy loss. While there have been various combinations of neural nets and SVMs in prior art, our results using L2-SVMs show that by simply replacing softmax with linear SVMs gives significant gains on popular deep learning datasets MNIST, CIFAR-10, and the ICML 2013 Representation Learning Workshop's face expression recognition challenge.},
  archivePrefix = {arXiv},
  eprint = {1306.0239},
  eprinttype = {arxiv},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\LYKKBDTI\\Tang - 2015 - Deep Learning using Linear Support Vector Machines.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\NNLC5RI6\\1306.html},
  journal = {arXiv:1306.0239 [cs, stat]},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  note = {Comment: Contribution to the ICML 2013 Challenges in Representation Learning Workshop},
  primaryClass = {cs, stat}
}

@inproceedings{taubin_curve_1995,
  title = {Curve and Surface Smoothing without Shrinkage},
  booktitle = {Proceedings of {{IEEE International Conference}} on {{Computer Vision}}},
  author = {Taubin, G.},
  year = {1995},
  month = jun,
  pages = {852--857},
  doi = {10.1109/ICCV.1995.466848},
  abstract = {For a number of computational purposes, including visualization of scientific data and registration of multimodal medical data, smooth curves must be approximated by polygonal curves, and surfaces by polyhedral surfaces. An inherent problem of these approximation algorithms is that the resulting curves and surfaces appear faceted. Boundary-following and iso-surface construction algorithms are typical examples. To reduce the apparent faceting, smoothing methods are used. In this paper, we introduce a new method for smoothing piecewise linear shapes of arbitrary dimension and topology. This new method is in fact a linear low-pass filter that removes high-curvature variations, and does not produce shrinkage. Its computational complexity is linear in the number of edges or faces of the shape, and the required storage is linear in the number of vertices.{$<>$}},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\EHTEXJNW\\Taubin - 1995 - Curve and surface smoothing without shrinkage.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\RJTP4AVH\\466848.html},
  keywords = {approximation algorithms,Approximation algorithms,boundary-following algorithms,computational complexity,Computational complexity,computational geometry,computer vision,curve fitting,curve smoothing,data visualisation,Data visualization,edges,faces,faceting,high curvature variations,image registration,iso-surface construction algorithms,linear low-pass filter,Low pass filters,medical image processing,multimodal medical data registration,Nonlinear filters,Piecewise linear approximation,piecewise linear shapes,Piecewise linear techniques,piecewise-linear techniques,polygonal curves,polyhedral surfaces,required storage,scientific data visualization,Shape,shrinkage,smoothing methods,Smoothing methods,surface smoothing,topology,Topology,vertices}
}

@article{ten_harmsel_emergency_2017,
  title = {Emergency {{Flight Planning}} for an {{Energy}}-{{Constrained Multicopter}}},
  author = {Ten Harmsel, Alec J. and Olson, Isaac J. and Atkins, Ella M.},
  year = {2017},
  month = jan,
  volume = {85},
  pages = {145--165},
  issn = {1573-0409},
  doi = {10.1007/s10846-016-0370-z},
  abstract = {Small Unmanned Aircraft Systems (UAS) have diverse commercial applications. Risk mitigation techniques must be developed to minimize the probability of harm to persons and property in the vicinity of the aircraft. This paper presents an emergency flight planner combining sensor-based and map-based elements to collectively plan a landing path for a UAS that experiences an unexpected low energy condition while flying over a populated area. Focus is placed in this work on the use of public databases of population distribution, structure locations, and terrain to create an efficient-to-access cost map of the data. Safe landing plans are generated with an A* search algorithm shown to be feasible for real-time use with the cost map. Simulation-based case studies are presented of a quadrotor UAS operating within New York City to illustrate how different cost terms impact optimal path characteristics.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\FLH6DRP5\\Ten Harmsel et al. - 2017 - Emergency Flight Planning for an Energy-Constraine.pdf},
  journal = {Journal of Intelligent \& Robotic Systems},
  language = {en},
  number = {1}
}

@book{the_cgal_project_cgal_2019,
  title = {{{CGAL User}} and {{Reference Manual}}},
  author = {{The CGAL Project}},
  year = {2019},
  edition = {4.14},
  publisher = {{CGAL Editorial Board}}
}

@inproceedings{theodore_flight_2006,
  title = {Flight {{Trials}} of a {{Rotorcraft Unmanned Aerial Vehicle Landing Autonomously}} at {{Unprepared Sites}}},
  booktitle = {Annual {{Forum Proc}}. {{American Helicopter Society}}},
  author = {Theodore, C. and Rowley, D. and Ansar, A. and Matthies, L. and Goldberg, S. and Hubbard, D. and Whalley, M.},
  year = {2006},
  volume = {62},
  pages = {1250}
}

@article{toony_describing_2015,
  title = {Describing {{3D Geometric Primitives Using}} the {{Gaussian Sphere}} and the {{Gaussian Accumulator}}},
  author = {Toony, Zahra and Laurendeau, Denis and Gagn{\'e}, Christian},
  year = {2015},
  month = nov,
  volume = {6},
  pages = {42},
  issn = {2092-6731},
  doi = {10.1007/s13319-015-0074-3},
  abstract = {Most complex object models are composed of basic parts or primitives. Being able to decompose a complex 3D model into such basic primitives is an important step in reverse engineering. Even when an algorithm can segment a complex model into its primitives, a description technique is still needed in order to identify the type of each primitive. Most feature extraction methods fail to describe these basic primitives or need a trained classifier on a database of prepared data to perform this identification. In this paper, we propose a method that can describe basic primitives such as planes, cones, cylinders, spheres, and tori as well as partial models of the latter four primitives. To achieve this task, we combine the concept of Gaussian sphere to a new concept introduced in this paper: the Gaussian accumulator. Comparison of the results of our method with other feature extractors reveals that our approach can distinguish all of these primitives from each other including partial models. Our method was also tested on real scanned data with noise and missing areas. The results show that our method is able to distinguish all of these models as well.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\W57YPWTT\\Toony et al. - 2015 - Describing 3D Geometric Primitives Using the Gauss.pdf},
  journal = {3D Research},
  keywords = {gaussian,sphere,triangle},
  language = {en},
  number = {4}
}

@article{torr_mlesac_2000,
  title = {{{MLESAC}}: {{A New Robust Estimator}} with {{Application}} to {{Estimating Image Geometry}}},
  shorttitle = {{{MLESAC}}},
  author = {Torr, P.H.S. and Zisserman, A.},
  year = {2000},
  month = apr,
  volume = {78},
  pages = {138--156},
  issn = {10773142},
  doi = {10.1006/cviu.1999.0832},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\PSC4X23V\\Torr and Zisserman - 2000 - MLESAC A New Robust Estimator with Application to.pdf},
  journal = {Computer Vision and Image Understanding},
  language = {en},
  number = {1}
}

@inproceedings{trevor2013efficient,
  title = {Efficient Organized Point Cloud Segmentation with Connected Components},
  booktitle = {3rd Workshop on Semantic Perception Mapping and Exploration ({{SPME}}), Karlsruhe, Germany},
  author = {Trevor, A and Gedikli, Suat and Rusu, R and Christensen, H},
  year = {2013}
}

@misc{usgs_lidar_2018_ny,
  title = {{{LIDAR Point Cloud NY CMPG}} 2013},
  author = {{USGS}},
  year = {2018},
  annotation = {Published: ftp://rockyftp.cr.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/USGS\_Lidar\_Point\_Cloud\_NY\_CMPG\_2013\_LAS\_2015/metadata},
  note = {Accessed: 2018-09-05}
}

@misc{usgs_lidar_2018-annarbor,
  title = {Lidar {{Point Cloud}}; {{Washtenaw County}}, {{MI}}},
  author = {{USGS}},
  year = {2018},
  annotation = {Published: ftp://rockyftp.cr.usgs.gov/vdelivery/Datasets/Staged/Elevation/LPC/Projects/MI\_WashtenawCo\_2009/laz},
  note = {Accessed: 2018-09-05}
}

@misc{lidar_germany,
  author = {{Open NRW}},
  title = {{Open Geo Data}},
  howpublished = {\url{https://www.opengeodata.nrw.de/produkte/geobasis/dom/dom1l/}},
  note = {Accessed: 2017-09-05},
  year={2018}
}

@article{van_der_walt_scikit-image_2014,
  title = {Scikit-Image: Image Processing in {{Python}}},
  author = {{Van der Walt}, St{\'e}fan and Sch{\"o}nberger, Johannes L. and {Nunez-Iglesias}, Juan and Boulogne, Fran{\c c}ois and Warner, Joshua D. and Yager, Neil and Gouillart, Emmanuelle and Yu, Tony and scikit-image {contributors}, the},
  year = {2014},
  month = jun,
  volume = {2},
  pages = {e453},
  issn = {2167-8359},
  doi = {10.7717/peerj.453},
  journal = {PeerJ Inc.},
  keywords = {Education,Image processing,Open source,Python,Reproducible research,Scientific programming,Visualization}
}

@inproceedings{van_sandt_efficiently_2019,
  title = {Efficiently {{Searching In}}-{{Memory Sorted Arrays}}: {{Revenge}} of the {{Interpolation Search}}?},
  shorttitle = {Efficiently {{Searching In}}-{{Memory Sorted Arrays}}},
  booktitle = {Proceedings of the 2019 {{International Conference}} on {{Management}} of {{Data}}},
  author = {Van Sandt, Peter and Chronis, Yannis and Patel, Jignesh M.},
  year = {2019},
  month = jun,
  pages = {36--53},
  publisher = {{Association for Computing Machinery}},
  address = {{Amsterdam, Netherlands}},
  doi = {10.1145/3299869.3300075},
  abstract = {In this paper, we focus on the problem of searching sorted, in-memory datasets. This is a key data operation, and Binary Search is the de facto algorithm that is used in practice. We consider an alternative, namely Interpolation Search, which can take advantage of hardware trends by using complex calculations to save memory accesses. Historically, Interpolation Search was found to underperform compared to other search algorithms in this setting, despite its superior asymptotic complexity. Also, Interpolation Search is known to perform poorly on non-uniform data. To address these issues, we introduce SIP (Slope reuse Interpolation), an optimized implementation of Interpolation Search, and TIP (Three point Interpolation), a new search algorithm that uses linear fractions to interpolate on non-uniform distributions. We evaluate these two algorithms against a similarly optimized Binary Search method using a variety of real and synthetic datasets. We show that SIP is up to 4 times faster on uniformly distributed data and TIP is 2-3 times faster on non-uniformly distributed data in some cases. We also design a meta-algorithm to switch between these different methods to automate picking the higher performing search algorithm, which depends on factors like data distribution.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\8VR4QHDZ\\Van Sandt et al. - 2019 - Efficiently Searching In-Memory Sorted Arrays Rev.pdf},
  isbn = {978-1-4503-5643-5},
  keywords = {binary search,in-memory search,interpolation,interpolation search,search},
  series = {{{SIGMOD}} '19}
}

@article{virtanen_scipy_2020,
  title = {{{SciPy}} 1.0: {{Fundamental Algorithms}} for {{Scientific Computing}} in {{Python}}},
  author = {Virtanen, Pauli and Gommers, Ralf and Oliphant, Travis E. and Haberland, Matt and Reddy, Tyler and Cournapeau, David and Burovski, Evgeni and Peterson, Pearu and Weckesser, Warren and Bright, Jonathan and {van der Walt}, St{\'e}fan J. and Brett, Matthew and Wilson, Joshua and Millman, K. Jarrod and Mayorov, Nikolay and Nelson, Andrew R. J. and Jones, Eric and Kern, Robert and Larson, Eric and Carey, C J and Polat, Ilhan and Feng, Yu and Moore, Eric W. and VanderPlas, Jake and Laxalde, Denis and Perktold, Josef and Cimrman, Robert and Henriksen, Ian and Quintero, E. A. and Harris, Charles R. and Archibald, Anne M. and Ribeiro, Ant{\^o}nio H. and Pedregosa, Fabian and {van Mulbregt}, Paul and {SciPy 1.0 Contributors}},
  year = {2020},
  volume = {17},
  pages = {261--272},
  doi = {10.1038/s41592-019-0686-2},
  journal = {Nature Methods}
}

@incollection{warren_enabling_2015,
  title = {Enabling {{Aircraft Emergency Landings Using Active Visual Site Detection}}},
  booktitle = {Field and {{Service Robotics}}: {{Results}} of the 9th {{International Conference}}},
  author = {Warren, Michael and Mejias, Luis and Yang, Xilin and Arain, Bilal and Gonzalez, Felipe and Upcroft, Ben},
  editor = {Mejias, Luis and Corke, Peter and Roberts, Jonathan},
  year = {2015},
  pages = {167--181},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-07488-7_12},
  abstract = {The ability to automate forced landings in an emergency such as engine failure is an essential ability to improve the safety of Unmanned Aerial Vehicles operating in General Aviation airspace. By using active vision to detect safe landing zones below the aircraft, the reliability and safety of such systems is vastly improved by gathering up-to-the-minute information about the ground environment. This paper presents the Site Detection System, a methodology utilising a downward facing camera to analyse the ground environment in both 2D and 3D, detect safe landing sites and characterise them according to size, shape, slope and nearby obstacles. A methodology is presented showing the fusion of landing site detection from 2D imagery with a coarse Digital Elevation Map and dense 3D reconstructions using INS-aided Structure-from-Motion to improve accuracy. Results are presented from an experimental flight showing the precision/recall of landing sites in comparison to a hand-classified ground truth, and improved performance with the integration of 3D analysis from visual Structure-from-Motion.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\HBG9S8VV\\Warren et al. - 2015 - Enabling Aircraft Emergency Landings Using Active .pdf},
  isbn = {978-3-319-07488-7},
  keywords = {Autonomous Helicopter,Landing Site,Site Detection,Unmanned Aerial Vehicle,Visual Odometry},
  language = {en},
  series = {Springer {{Tracts}} in {{Advanced Robotics}}}
}

@article{weiss_survey_2016,
  title = {A Survey of Transfer Learning},
  author = {Weiss, Karl and Khoshgoftaar, Taghi M. and Wang, DingDing},
  year = {2016},
  month = may,
  volume = {3},
  pages = {9},
  issn = {2196-1115},
  doi = {10.1186/s40537-016-0043-6},
  abstract = {Machine learning and data mining techniques have been used in numerous real-world applications. An assumption of traditional machine learning methodologies is the training data and testing data are taken from the same domain, such that the input feature space and data distribution characteristics are the same. However, in some real-world machine learning scenarios, this assumption does not hold. There are cases where training data is expensive or difficult to collect. Therefore, there is a need to create high-performance learners trained with more easily obtained data from different domains. This methodology is referred to as transfer learning. This survey paper formally defines transfer learning, presents information on current solutions, and reviews applications applied to transfer learning. Lastly, there is information listed on software downloads for various transfer learning solutions and a discussion of possible future research work. The transfer learning solutions surveyed are independent of data size and can be applied to big data environments.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\4V3X3CMC\\Weiss et al. - 2016 - A survey of transfer learning.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\42842R2H\\s40537-016-0043-6.html},
  journal = {Journal of Big Data},
  number = {1}
}

@book{wenninger_spherical_1999,
  title = {Spherical Models},
  author = {Wenninger, Magnus J},
  year = {1999},
  volume = {3},
  publisher = {{Courier Corporation}}
}

@article{winnefeld_unmanned_2011,
  title = {Unmanned {{Systems Integrated Roadmap FY}} 2011-2036},
  author = {Winnefeld, J. A. and Kendall, F.},
  year = {2011},
  journal = {Office of the Secretary of Defense. US}
}

@inproceedings{xu_spidercnn_2018,
  title = {{{SpiderCNN}}: {{Deep Learning}} on {{Point Sets}} with {{Parameterized Convolutional Filters}}},
  shorttitle = {{{SpiderCNN}}},
  booktitle = {Computer {{Vision}} \textendash{} {{ECCV}} 2018},
  author = {Xu, Yifan and Fan, Tianqi and Xu, Mingye and Zeng, Long and Qiao, Yu},
  editor = {Ferrari, Vittorio and Hebert, Martial and Sminchisescu, Cristian and Weiss, Yair},
  year = {2018},
  pages = {90--105},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-01237-3_6},
  abstract = {Deep neural networks have enjoyed remarkable success for various vision tasks, however it remains challenging to apply CNNs to domains lacking a regular underlying structures such as 3D point clouds. Towards this we propose a novel convolutional architecture, termed SpiderCNN, to efficiently extract geometric features from point clouds. SpiderCNN is comprised of units called SpiderConv, which extend convolutional operations from regular grids to irregular point sets that can be embedded in RnRn\textbackslash mathbb \{R\}\^n, by parametrizing a family of convolutional filters. We design the filter as a product of a simple step function that captures local geodesic information and a Taylor polynomial that ensures the expressiveness. SpiderCNN inherits the multi-scale hierarchical architecture from classical CNNs, which allows it to extract semantic deep features. Experiments on ModelNet40 demonstrate that SpiderCNN achieves state-of-the-art accuracy 92.4\%92.4\%92.4 \textbackslash\% on standard benchmarks, and shows competitive performance on segmentation task.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\Y8WDATMZ\\Xu et al. - 2018 - SpiderCNN Deep Learning on Point Sets with Parame.pdf},
  isbn = {978-3-030-01237-3},
  keywords = {Convolutional neural network,Parametrized convolutional filters,Point clouds},
  language = {en},
  series = {Lecture {{Notes}} in {{Computer Science}}}
}

@article{yan_dynamic_2017,
  title = {A {{Dynamic Multi}}-{{Projection}}-{{Contour Approximating Framework}} for the {{3D Reconstruction}} of {{Buildings}} by {{Super}}-{{Generalized Optical Stereo}}-{{Pairs}}},
  author = {Yan, Yiming and Su, Nan and Zhao, Chunhui and Wang, Liguo},
  year = {2017},
  month = sep,
  volume = {17},
  pages = {2153},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  doi = {10.3390/s17092153},
  abstract = {In this paper, a novel framework of the 3D reconstruction of buildings is proposed, focusing on remote sensing super-generalized stereo-pairs (SGSPs). As we all know, 3D reconstruction cannot be well performed using nonstandard stereo pairs, since reliable stereo matching could not be achieved when the image-pairs are collected at a great difference of views, and we always failed to obtain dense 3D points for regions of buildings, and cannot do further 3D shape reconstruction. We defined SGSPs as two or more optical images collected in less constrained views but covering the same buildings. It is even more difficult to reconstruct the 3D shape of a building by SGSPs using traditional frameworks. As a result, a dynamic multi-projection-contour approximating (DMPCA) framework was introduced for SGSP-based 3D reconstruction. The key idea is that we do an optimization to find a group of parameters of a simulated 3D model and use a binary feature-image that minimizes the total differences between projection-contours of the building in the SGSPs and that in the simulated 3D model. Then, the simulated 3D model, defined by the group of parameters, could approximate the actual 3D shape of the building. Certain parameterized 3D basic-unit-models of typical buildings were designed, and a simulated projection system was established to obtain a simulated projection-contour in different views. Moreover, the artificial bee colony algorithm was employed to solve the optimization. With SGSPs collected by the satellite and our unmanned aerial vehicle, the DMPCA framework was verified by a group of experiments, which demonstrated the reliability and advantages of this work.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\2Z7P3RVG\\Yan et al. - 2017 - A Dynamic Multi-Projection-Contour Approximating F.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\HXRWEQL5\\2153.html},
  journal = {Sensors},
  keywords = {3D reconstruction,artificial bee colony algorithm,remote sensing,super-generalized stereo-pairs},
  language = {en},
  number = {9}
}

@article{yan_hierarchical_2017,
  title = {A {{Hierarchical Building Segmentation}} in {{Digital Surface Models}} for {{3D Reconstruction}}},
  author = {Yan, Yiming and Gao, Fengjiao and Deng, Shupei and Su, Nan},
  year = {2017},
  month = feb,
  volume = {17},
  pages = {222},
  publisher = {{Multidisciplinary Digital Publishing Institute}},
  doi = {10.3390/s17020222},
  abstract = {In this study, a hierarchical method for segmenting buildings in a digital surface model (DSM), which is used in a novel framework for 3D reconstruction, is proposed. Most 3D reconstructions of buildings are model-based. However, the limitations of these methods are overreliance on completeness of the offline-constructed models of buildings, and the completeness is not easily guaranteed since in modern cities buildings can be of a variety of types. Therefore, a model-free framework using high precision DSM and texture-images buildings was introduced. There are two key problems with this framework. The first one is how to accurately extract the buildings from the DSM. Most segmentation methods are limited by either the terrain factors or the difficult choice of parameter-settings. A level-set method are employed to roughly find the building regions in the DSM, and then a recently proposed `occlusions of random textures model' are used to enhance the local segmentation of the buildings. The second problem is how to generate the facades of buildings. Synergizing with the corresponding texture-images, we propose a roof-contour guided interpolation of building facades. The 3D reconstruction results achieved by airborne-like images and satellites are compared. Experiments show that the segmentation method has good performance, and 3D reconstruction is easily performed by our framework, and better visualization results can be obtained by airborne-like images, which can be further replaced by UAV images.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\JXAEMK4A\\Yan et al. - 2017 - A Hierarchical Building Segmentation in Digital Su.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\JUR5KH3T\\222.html},
  journal = {Sensors},
  keywords = {3D reconstruction,building segmentation,digital surface model,remote sensing},
  language = {en},
  number = {2}
}

@article{zheng_bilateral_2011,
  title = {Bilateral Normal Filtering for Mesh Denoising},
  author = {Zheng, Youyi and Fu, Hongbo and Au, Oscar Kin-Chung and Tai, Chiew-Lan},
  year = {2011},
  month = oct,
  volume = {17},
  pages = {1521--1530},
  issn = {1941-0506},
  doi = {10.1109/TVCG.2010.264},
  abstract = {Decoupling local geometric features from the spatial location of a mesh is crucial for feature-preserving mesh denoising. This paper focuses on first order features, i.e., facet normals, and presents a simple yet effective anisotropic mesh denoising framework via normal field denoising. Unlike previous denoising methods based on normal filtering, which process normals defined on the Gauss sphere, our method considers normals as a surface signal defined over the original mesh. This allows the design of a novel bilateral normal filter that depends on both spatial distance and signal distance. Our bilateral filter is a more natural extension of the elegant bilateral filter for image denoising than those used in previous bilateral mesh denoising methods. Besides applying this bilateral normal filter in a local, iterative scheme, as common in most of previous works, we present for the first time a global, noniterative scheme for an isotropic denoising. We show that the former scheme is faster and more effective for denoising extremely noisy meshes while the latter scheme is more robust to irregular surface sampling. We demonstrate that both our feature-preserving schemes generally produce visually and numerically better denoising results than previous methods, especially at challenging regions with sharp features or irregular sampling.},
  journal = {IEEE transactions on visualization and computer graphics},
  language = {eng},
  number = {10},
  pmid = {21173457}
}

@article{zhou_dense_2013,
  title = {Dense Scene Reconstruction with Points of Interest},
  author = {Zhou, Qian-Yi and Koltun, Vladlen},
  year = {2013},
  month = jul,
  volume = {32},
  pages = {112:1--112:8},
  issn = {0730-0301},
  doi = {10.1145/2461912.2461919},
  abstract = {We present an approach to detailed reconstruction of complex real-world scenes with a handheld commodity range sensor. The user moves the sensor freely through the environment and images the scene. An offline registration and integration pipeline produces a detailed scene model. To deal with the complex sensor trajectories required to produce detailed reconstructions with a consumer-grade sensor, our pipeline detects points of interest in the scene and preserves detailed geometry around them while a global optimization distributes residual registration errors through the environment. Our results demonstrate that detailed reconstructions of complex scenes can be obtained with a consumer-grade camera.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\PGGD8ZLQ\\Zhou and Koltun - 2013 - Dense scene reconstruction with points of interest.pdf},
  journal = {ACM Transactions on Graphics},
  keywords = {range imaging,scene reconstruction},
  number = {4}
}

@article{zhou_open3d_2018,
  title = {{{Open3D}}: {{A}} Modern Library for {{3D}} Data Processing},
  author = {Zhou, Qian-Yi and Park, Jaesik and Koltun, Vladlen},
  year = {2018},
  archivePrefix = {arXiv},
  eprint = {1801.09847},
  eprinttype = {arxiv},
  journal = {arXiv preprint arXiv:1801.09847}
}

@article{zhou_seamless_2014,
  title = {Seamless {{Fusion}} of {{LiDAR}} and {{Aerial Imagery}} for {{Building Extraction}}},
  author = {Zhou, G. and Zhou, X.},
  year = {2014},
  month = nov,
  volume = {52},
  pages = {7393--7407},
  issn = {1558-0644},
  doi = {10.1109/TGRS.2014.2311991},
  abstract = {Although many efforts have been made on the fusion of Light Detection and Ranging (LiDAR) and aerial imagery for the extraction of houses, little research on taking advantage of a building's geometric features, properties, and structures for assisting the further fusion of the two types of data has been made. For this reason, this paper develops a seamless fusion between LiDAR and aerial imagery on the basis of aspect graphs, which utilize the features of houses, such as geometry, structures, and shapes. First, 3-D primitives, standing for houses, are chosen, and their projections are represented by the aspects. A hierarchical aspect graph is then constructed using aerial image processing in combination with the results of LiDAR data processing. In the aspect graph, the note represents the face aspect and the arc is described by attributes obtained by the formulated coding regulations, and the coregistration between the aspect and LiDAR data is implemented. As a consequence, the aspects and/or the aspect graph are interpreted for the extraction of houses, and then the houses are fitted using a planar equation for creating a digital building model (DBM). The experimental field, which is located in Wytheville, VA, is used to evaluate the proposed method. The experimental results demonstrated that the proposed method is capable of effectively extracting houses at a successful rate of 93\%, as compared with another method, which is 82\% effective when LiDAR spacing is approximately 7.3 by 7.3 ft2. The accuracy of 3-D DBM is higher than the method using only single LiDAR data.},
  file = {C\:\\Users\\Jeremy\\Zotero\\storage\\7HNQ4L7E\\Zhou and Zhou - 2014 - Seamless Fusion of LiDAR and Aerial Imagery for Bu.pdf;C\:\\Users\\Jeremy\\Zotero\\storage\\C97YPDLL\\6804760.html},
  journal = {IEEE Transactions on Geoscience and Remote Sensing},
  keywords = {3D primitive,Aerial image,aerial image processing,building extraction,building geometric feature,Buildings,DBM,digital building model,Encoding,extraction,Face,Feature extraction,formulated coding regulation,geophysical image processing,graph theory,hierarchical aspect graph,house,house extraction,image coding,image coregistration,image fusion,image processing,image registration,image representation,Laser radar,LiDAR data processing,light detection and ranging,light detection and ranging (LiDAR),Merging,Optical imaging,optical radar,radar imaging,seamless fusion,urban},
  number = {11}
}


@misc{satellite_germany,
  author= {{Land NRW}},
  title = {{Witten County Portal}},
  howpublished = {\url{https://www.land.nrw/de/tags/open-data}},
  note    = {Data was retrieved through ArcGIS World Imagery}, 
  year={2018}
}


@misc{satellite_newyork,
  author = {{New York State}},
  title = {{2016 Annual Lot New York County}},
  howpublished = {\url{http://gis.ny.gov/gateway/orthoprogram/lot16/new-york.htm}},
  note    = {Data was retrieved through ArcGIS World Imagery}, 
  year={2018}
}

@misc{satellite_annarbor,
  author = {{Microsoft}},
  title = {{Bing Maps}},
  howpublished = {\url{https://www.bing.com/maps}},
  note = {Accessed: 2018-09-05},
  year={2018}
}


@misc{polylidar_benchmark_concave,
  title = {{Github - Benchmark Concave Hull}},
  howpublished  = {\url{https://github.com/JeremyBYU/concavehull-evaluation}},
  note = {Accessed: 2020-01-05},
  year={2020}
}

@misc{marl,
  title = {{Github - A Hybrid Thread/Fiber Task Scheduler}},
  howpublished  = {\url{https://github.com/google/marl}},
  note = {Accessed: 2020-06-05},
  year={2020}
}


